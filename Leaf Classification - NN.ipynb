{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaf Classfication \n",
    "A For CZ4041 Machine Learning Assignment from PT3 in AY2018/2019 Semester 2.\n",
    "The group members are:\n",
    "- LIU Yiqing\n",
    "- LUO Bingyi\n",
    "- TENG He Xu\n",
    "- WANG Jia\n",
    "- YI Zhiyue\n",
    "- ZHAO Ziru\n",
    "\n",
    "The Kaggle problem is here https://www.kaggle.com/c/leaf-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries and Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import History \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histories are to record model losses in every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = History()\n",
    "history2 = History()\n",
    "history3 = History()\n",
    "history4 = History()\n",
    "history5 = History()\n",
    "\n",
    "LABEL_PATH = 'data/'\n",
    "TRAIN_FILE_NAME = 'train.csv'\n",
    "TEST_FILE_NAME = 'test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load From CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load features and labels from the train csv file\n",
    "\n",
    "y is extracted from the `species` column and converted from text string to numeric values as classes\n",
    "\n",
    "x contains features in the remaining columns except `id` columns. `StandardScaler` is used to transform the data so that its distribution will have a `mean = 0` and standard `deviation = 1`. It is to standardize the scale of the data for ease of computation and remain the features unaffected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_frame = pd.read_csv(LABEL_PATH + TRAIN_FILE_NAME)\n",
    "\n",
    "train_data_frame = train_data_frame.drop(['id'], axis=1)\n",
    "\n",
    "y = train_data_frame.pop('species')\n",
    "classes = np.unique(y)\n",
    "\n",
    "y = to_categorical(LabelEncoder().fit(y).transform(y))\n",
    "\n",
    "x = StandardScaler().fit(train_data_frame).transform(train_data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `StratifiedShuffleSplit` to randomly split the data set into training data and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_1 dimention:  (891, 99)\n",
      "validate_x_1 dimention:    (99, 192)\n",
      "train_x_2 dimention:  (891, 99)\n",
      "validate_x_2 dimention:    (99, 192)\n",
      "train_x_3 dimention:  (891, 99)\n",
      "validate_x_3 dimention:    (99, 192)\n"
     ]
    }
   ],
   "source": [
    "sss_1 = StratifiedShuffleSplit(n_splits=10, test_size=0.1)\n",
    "sss_2 = StratifiedShuffleSplit(n_splits=20, test_size=0.1)\n",
    "sss_3 = StratifiedShuffleSplit(n_splits=30, test_size=0.1)\n",
    "\n",
    "train_index_1, validation_index_1 = next(iter(sss_1.split(x, y)))\n",
    "train_x_1, validate_x_1 = x[train_index_1], x[validation_index_1]\n",
    "train_y_1, validate_y_1 = y[train_index_1], y[validation_index_1]\n",
    "\n",
    "train_index_2, validation_index_2 = next(iter(sss_2.split(x, y)))\n",
    "train_x_2, validate_x_2 = x[train_index_2], x[validation_index_2]\n",
    "train_y_2, validate_y_2 = y[train_index_2], y[validation_index_2]\n",
    "\n",
    "train_index_3, validation_index_3 = next(iter(sss_3.split(x, y)))\n",
    "train_x_3, validate_x_3 = x[train_index_3], x[validation_index_3]\n",
    "train_y_3, validate_y_3 = y[train_index_3], y[validation_index_3]\n",
    "\n",
    "print(\"train_x_1 dimention: \",train_y_1.shape)\n",
    "print(\"validate_x_1 dimention:   \",validate_x_1.shape)\n",
    "\n",
    "print(\"train_x_2 dimention: \",train_y_2.shape)\n",
    "print(\"validate_x_2 dimention:   \",validate_x_2.shape)\n",
    "\n",
    "print(\"train_x_3 dimention: \",train_y_3.shape)\n",
    "print(\"validate_x_3 dimention:   \",validate_x_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of classes for later computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_classes = len(np.unique(train_y_1, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "\n",
    "Use ensemble learning method to predict the value.\n",
    "\n",
    "Ensemble learning refers to training multiple models with the same set of training data set and validation data set. With multiple sets of models, a pool of predicted values can be generated. We can pick the most possible predicted value from the pool to achieve the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lane0\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2048, kernel_initializer=\"uniform\", input_dim=192, activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Dense(2048, init='uniform', activation='relu', input_dim = x.shape[1]))\n",
    "model1.add(Dropout(0.3))\n",
    "model1.add(Dense(1024, activation='sigmoid'))\n",
    "model1.add(Dropout(0.3))\n",
    "model1.add(Dense(no_of_classes, activation=tf.nn.softmax))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lane0\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2048, kernel_initializer=\"uniform\", input_dim=192, activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(2048, init='uniform', activation='relu', input_dim = x.shape[1]))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(1024, activation='sigmoid'))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(no_of_classes, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lane0\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2048, kernel_initializer=\"uniform\", input_dim=192, activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Dense(2048, init='uniform', activation='relu', input_dim = x.shape[1]))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Dense(1024, activation='sigmoid'))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Dense(no_of_classes, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lane0\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2048, kernel_initializer=\"uniform\", input_dim=192, activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "\n",
    "model4.add(Dense(2048, init='uniform', activation='relu', input_dim = x.shape[1]))\n",
    "model4.add(Dropout(0.3))\n",
    "model4.add(Dense(1024, activation='sigmoid'))\n",
    "model4.add(Dropout(0.3))\n",
    "model4.add(Dense(no_of_classes, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lane0\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2048, kernel_initializer=\"uniform\", input_dim=192, activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "\n",
    "model5.add(Dense(2048, init='uniform', activation='relu', input_dim = x.shape[1]))\n",
    "model5.add(Dropout(0.3))\n",
    "model5.add(Dense(1024, activation='sigmoid'))\n",
    "model5.add(Dropout(0.3))\n",
    "model5.add(Dense(no_of_classes, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and fit the model\n",
    "\n",
    "At this stage, the data is pumped into the model and Keras will help to run iterations to reduce the loss as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lane0\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 891 samples, validate on 99 samples\n",
      "Epoch 1/150\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 4.1363 - acc: 0.1785 - val_loss: 2.9080 - val_acc: 0.5758\n",
      "Epoch 2/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 2.2328 - acc: 0.6667 - val_loss: 1.6381 - val_acc: 0.8586\n",
      "Epoch 3/150\n",
      "891/891 [==============================] - 1s 565us/step - loss: 1.2125 - acc: 0.8676 - val_loss: 1.0054 - val_acc: 0.8889\n",
      "Epoch 4/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.6818 - acc: 0.9270 - val_loss: 0.5820 - val_acc: 0.9596\n",
      "Epoch 5/150\n",
      "891/891 [==============================] - 1s 625us/step - loss: 0.4135 - acc: 0.9641 - val_loss: 0.3847 - val_acc: 0.9798\n",
      "Epoch 6/150\n",
      "891/891 [==============================] - 1s 629us/step - loss: 0.2787 - acc: 0.9877 - val_loss: 0.3097 - val_acc: 0.9899\n",
      "Epoch 7/150\n",
      "891/891 [==============================] - 1s 634us/step - loss: 0.2069 - acc: 0.9888 - val_loss: 0.2426 - val_acc: 0.9899\n",
      "Epoch 8/150\n",
      "891/891 [==============================] - 1s 643us/step - loss: 0.1640 - acc: 0.9899 - val_loss: 0.1881 - val_acc: 1.0000\n",
      "Epoch 9/150\n",
      "891/891 [==============================] - 1s 603us/step - loss: 0.1228 - acc: 0.9989 - val_loss: 0.1635 - val_acc: 1.0000\n",
      "Epoch 10/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.1011 - acc: 0.9966 - val_loss: 0.1431 - val_acc: 1.0000\n",
      "Epoch 11/150\n",
      "891/891 [==============================] - 1s 584us/step - loss: 0.0905 - acc: 0.9978 - val_loss: 0.1265 - val_acc: 1.0000\n",
      "Epoch 12/150\n",
      "891/891 [==============================] - 1s 587us/step - loss: 0.0749 - acc: 0.9989 - val_loss: 0.1182 - val_acc: 1.0000\n",
      "Epoch 13/150\n",
      "891/891 [==============================] - 1s 600us/step - loss: 0.0688 - acc: 0.9989 - val_loss: 0.1136 - val_acc: 1.0000\n",
      "Epoch 14/150\n",
      "891/891 [==============================] - 1s 602us/step - loss: 0.0645 - acc: 0.9978 - val_loss: 0.1039 - val_acc: 1.0000\n",
      "Epoch 15/150\n",
      "891/891 [==============================] - 1s 594us/step - loss: 0.0614 - acc: 0.9955 - val_loss: 0.0976 - val_acc: 1.0000\n",
      "Epoch 16/150\n",
      "891/891 [==============================] - 1s 598us/step - loss: 0.0514 - acc: 0.9989 - val_loss: 0.0851 - val_acc: 1.0000\n",
      "Epoch 17/150\n",
      "891/891 [==============================] - 1s 593us/step - loss: 0.0480 - acc: 0.9989 - val_loss: 0.0781 - val_acc: 1.0000\n",
      "Epoch 18/150\n",
      "891/891 [==============================] - 1s 584us/step - loss: 0.0431 - acc: 0.9989 - val_loss: 0.0779 - val_acc: 1.0000\n",
      "Epoch 19/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0399 - acc: 1.0000 - val_loss: 0.0790 - val_acc: 1.0000\n",
      "Epoch 20/150\n",
      "891/891 [==============================] - 1s 593us/step - loss: 0.0365 - acc: 1.0000 - val_loss: 0.0780 - val_acc: 1.0000\n",
      "Epoch 21/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0363 - acc: 1.0000 - val_loss: 0.0759 - val_acc: 1.0000\n",
      "Epoch 22/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0328 - acc: 1.0000 - val_loss: 0.0720 - val_acc: 1.0000\n",
      "Epoch 23/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0332 - acc: 1.0000 - val_loss: 0.0690 - val_acc: 1.0000\n",
      "Epoch 24/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0302 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 1.0000\n",
      "Epoch 25/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0289 - acc: 1.0000 - val_loss: 0.0631 - val_acc: 1.0000\n",
      "Epoch 26/150\n",
      "891/891 [==============================] - 1s 570us/step - loss: 0.0287 - acc: 1.0000 - val_loss: 0.0600 - val_acc: 1.0000\n",
      "Epoch 27/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0240 - acc: 1.0000 - val_loss: 0.0577 - val_acc: 1.0000\n",
      "Epoch 28/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0256 - acc: 0.9989 - val_loss: 0.0558 - val_acc: 1.0000\n",
      "Epoch 29/150\n",
      "891/891 [==============================] - 1s 570us/step - loss: 0.0242 - acc: 1.0000 - val_loss: 0.0565 - val_acc: 1.0000\n",
      "Epoch 30/150\n",
      "891/891 [==============================] - 1s 581us/step - loss: 0.0218 - acc: 1.0000 - val_loss: 0.0555 - val_acc: 1.0000\n",
      "Epoch 31/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.0536 - val_acc: 1.0000\n",
      "Epoch 32/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.0507 - val_acc: 1.0000\n",
      "Epoch 33/150\n",
      "891/891 [==============================] - 1s 565us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.0487 - val_acc: 1.0000\n",
      "Epoch 34/150\n",
      "891/891 [==============================] - 1s 590us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.0490 - val_acc: 1.0000\n",
      "Epoch 35/150\n",
      "891/891 [==============================] - 1s 567us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.0487 - val_acc: 1.0000\n",
      "Epoch 36/150\n",
      "891/891 [==============================] - 1s 580us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.0470 - val_acc: 1.0000\n",
      "Epoch 37/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.0450 - val_acc: 1.0000\n",
      "Epoch 38/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.0435 - val_acc: 1.0000\n",
      "Epoch 39/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 1.0000\n",
      "Epoch 40/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.0446 - val_acc: 1.0000\n",
      "Epoch 41/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.0431 - val_acc: 1.0000\n",
      "Epoch 42/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0419 - val_acc: 1.0000\n",
      "Epoch 43/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.0416 - val_acc: 1.0000\n",
      "Epoch 44/150\n",
      "891/891 [==============================] - 1s 567us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.0409 - val_acc: 1.0000\n",
      "Epoch 45/150\n",
      "891/891 [==============================] - 1s 582us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 1.0000\n",
      "Epoch 46/150\n",
      "891/891 [==============================] - 1s 590us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0392 - val_acc: 1.0000\n",
      "Epoch 47/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.0388 - val_acc: 1.0000\n",
      "Epoch 48/150\n",
      "891/891 [==============================] - 1s 580us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0382 - val_acc: 1.0000\n",
      "Epoch 49/150\n",
      "891/891 [==============================] - 0s 560us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0378 - val_acc: 1.0000\n",
      "Epoch 50/150\n",
      "891/891 [==============================] - 1s 566us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0368 - val_acc: 1.0000\n",
      "Epoch 51/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0358 - val_acc: 1.0000\n",
      "Epoch 52/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.0350 - val_acc: 1.0000\n",
      "Epoch 53/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0347 - val_acc: 1.0000\n",
      "Epoch 54/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0339 - val_acc: 1.0000\n",
      "Epoch 55/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0327 - val_acc: 1.0000\n",
      "Epoch 56/150\n",
      "891/891 [==============================] - 0s 561us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0325 - val_acc: 1.0000\n",
      "Epoch 57/150\n",
      "891/891 [==============================] - 1s 568us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0321 - val_acc: 1.0000\n",
      "Epoch 58/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0322 - val_acc: 1.0000\n",
      "Epoch 59/150\n",
      "891/891 [==============================] - 1s 584us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0320 - val_acc: 1.0000\n",
      "Epoch 60/150\n",
      "891/891 [==============================] - 1s 613us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150\n",
      "891/891 [==============================] - 1s 612us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0317 - val_acc: 1.0000\n",
      "Epoch 62/150\n",
      "891/891 [==============================] - 1s 582us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 1.0000\n",
      "Epoch 63/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0310 - val_acc: 1.0000\n",
      "Epoch 64/150\n",
      "891/891 [==============================] - 0s 561us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0302 - val_acc: 1.0000\n",
      "Epoch 65/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0293 - val_acc: 1.0000\n",
      "Epoch 66/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0294 - val_acc: 1.0000\n",
      "Epoch 67/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0291 - val_acc: 1.0000\n",
      "Epoch 68/150\n",
      "891/891 [==============================] - 1s 568us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0290 - val_acc: 1.0000\n",
      "Epoch 69/150\n",
      "891/891 [==============================] - 1s 587us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0289 - val_acc: 1.0000\n",
      "Epoch 70/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0289 - val_acc: 1.0000\n",
      "Epoch 71/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0285 - val_acc: 1.0000\n",
      "Epoch 72/150\n",
      "891/891 [==============================] - 0s 559us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0281 - val_acc: 1.0000\n",
      "Epoch 73/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0278 - val_acc: 1.0000\n",
      "Epoch 74/150\n",
      "891/891 [==============================] - 1s 570us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0275 - val_acc: 1.0000\n",
      "Epoch 75/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0271 - val_acc: 1.0000\n",
      "Epoch 76/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0263 - val_acc: 1.0000\n",
      "Epoch 77/150\n",
      "891/891 [==============================] - 1s 592us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0262 - val_acc: 1.0000\n",
      "Epoch 78/150\n",
      "891/891 [==============================] - 1s 564us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0262 - val_acc: 1.0000\n",
      "Epoch 79/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0261 - val_acc: 1.0000\n",
      "Epoch 80/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0256 - val_acc: 1.0000\n",
      "Epoch 81/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0253 - val_acc: 1.0000\n",
      "Epoch 82/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 1.0000\n",
      "Epoch 83/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 1.0000\n",
      "Epoch 84/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 1.0000\n",
      "Epoch 85/150\n",
      "891/891 [==============================] - 1s 602us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 1.0000\n",
      "Epoch 86/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0247 - val_acc: 1.0000\n",
      "Epoch 87/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "Epoch 88/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 89/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0240 - val_acc: 1.0000\n",
      "Epoch 90/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0240 - val_acc: 1.0000\n",
      "Epoch 91/150\n",
      "891/891 [==============================] - 1s 582us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 92/150\n",
      "891/891 [==============================] - 1s 577us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 1.0000\n",
      "Epoch 93/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 1.0000\n",
      "Epoch 94/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0227 - val_acc: 1.0000\n",
      "Epoch 95/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0224 - val_acc: 1.0000\n",
      "Epoch 96/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 1.0000\n",
      "Epoch 97/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0221 - val_acc: 1.0000\n",
      "Epoch 98/150\n",
      "891/891 [==============================] - 1s 580us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 1.0000\n",
      "Epoch 99/150\n",
      "891/891 [==============================] - 1s 577us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0221 - val_acc: 1.0000\n",
      "Epoch 100/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 1.0000\n",
      "Epoch 101/150\n",
      "891/891 [==============================] - 1s 582us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 1.0000\n",
      "Epoch 102/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 1.0000\n",
      "Epoch 103/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 1.0000\n",
      "Epoch 104/150\n",
      "891/891 [==============================] - 1s 594us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 1.0000\n",
      "Epoch 105/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 1.0000\n",
      "Epoch 106/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 1.0000\n",
      "Epoch 107/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 1.0000\n",
      "Epoch 108/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 1.0000\n",
      "Epoch 109/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 1.0000\n",
      "Epoch 110/150\n",
      "891/891 [==============================] - 1s 584us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 1.0000\n",
      "Epoch 111/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
      "Epoch 112/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 1.0000\n",
      "Epoch 113/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 1.0000\n",
      "Epoch 114/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 1.0000\n",
      "Epoch 115/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 1.0000\n",
      "Epoch 116/150\n",
      "891/891 [==============================] - 1s 568us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 1.0000\n",
      "Epoch 117/150\n",
      "891/891 [==============================] - 1s 566us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 1.0000\n",
      "Epoch 118/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
      "Epoch 119/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 120/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 121/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 1s 589us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 122/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0179 - val_acc: 1.0000\n",
      "Epoch 123/150\n",
      "891/891 [==============================] - 1s 568us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 124/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 125/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 1.0000\n",
      "Epoch 126/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 127/150\n",
      "891/891 [==============================] - 1s 568us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 128/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 1.0000\n",
      "Epoch 129/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0179 - val_acc: 1.0000\n",
      "Epoch 130/150\n",
      "891/891 [==============================] - 1s 580us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 131/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0176 - val_acc: 1.0000\n",
      "Epoch 132/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 133/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 1.0000\n",
      "Epoch 134/150\n",
      "891/891 [==============================] - 1s 589us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 1.0000\n",
      "Epoch 135/150\n",
      "891/891 [==============================] - 1s 581us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 1.0000\n",
      "Epoch 136/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
      "Epoch 137/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
      "Epoch 138/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 1.0000\n",
      "Epoch 139/150\n",
      "891/891 [==============================] - 1s 589us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 1.0000\n",
      "Epoch 140/150\n",
      "891/891 [==============================] - 1s 591us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 1.0000\n",
      "Epoch 141/150\n",
      "891/891 [==============================] - 1s 586us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 142/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "Epoch 143/150\n",
      "891/891 [==============================] - 1s 594us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 144/150\n",
      "891/891 [==============================] - 1s 593us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 1.0000\n",
      "Epoch 145/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 1.0000\n",
      "Epoch 146/150\n",
      "891/891 [==============================] - 1s 603us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 1.0000\n",
      "Epoch 147/150\n",
      "891/891 [==============================] - 1s 587us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 148/150\n",
      "891/891 [==============================] - 1s 577us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 149/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 150/150\n",
      "891/891 [==============================] - 1s 582us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0154 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x148b4f1a748>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(loss='categorical_crossentropy',optimizer='Adamax', metrics = [\"accuracy\"])\n",
    "#model1.fit(train_x_1, train_y_1, epochs = 100, verbose=1, validation_data=(validate_x_1, validate_y_1), callbacks=[history1])\n",
    "model1.fit(x, y, nb_epoch=150, batch_size=100, verbose=1, callbacks=[history1], validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lane0\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 891 samples, validate on 99 samples\n",
      "Epoch 1/150\n",
      "891/891 [==============================] - 1s 2ms/step - loss: 4.1876 - acc: 0.1627 - val_loss: 2.9610 - val_acc: 0.5253\n",
      "Epoch 2/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 2.2752 - acc: 0.6622 - val_loss: 1.8211 - val_acc: 0.7980\n",
      "Epoch 3/150\n",
      "891/891 [==============================] - 1s 582us/step - loss: 1.2249 - acc: 0.8664 - val_loss: 1.0163 - val_acc: 0.9293\n",
      "Epoch 4/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 0.7079 - acc: 0.9383 - val_loss: 0.6043 - val_acc: 0.9495\n",
      "Epoch 5/150\n",
      "891/891 [==============================] - 1s 580us/step - loss: 0.4162 - acc: 0.9731 - val_loss: 0.4334 - val_acc: 0.9596\n",
      "Epoch 6/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.2863 - acc: 0.9843 - val_loss: 0.3160 - val_acc: 0.9798\n",
      "Epoch 7/150\n",
      "891/891 [==============================] - 1s 581us/step - loss: 0.2033 - acc: 0.9966 - val_loss: 0.2558 - val_acc: 0.9899\n",
      "Epoch 8/150\n",
      "891/891 [==============================] - 1s 588us/step - loss: 0.1564 - acc: 0.9910 - val_loss: 0.2218 - val_acc: 0.9899\n",
      "Epoch 9/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 0.1287 - acc: 0.9966 - val_loss: 0.1831 - val_acc: 1.0000\n",
      "Epoch 10/150\n",
      "891/891 [==============================] - 1s 570us/step - loss: 0.1080 - acc: 0.9966 - val_loss: 0.1635 - val_acc: 1.0000\n",
      "Epoch 11/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0893 - acc: 0.9966 - val_loss: 0.1567 - val_acc: 0.9798\n",
      "Epoch 12/150\n",
      "891/891 [==============================] - 1s 599us/step - loss: 0.0817 - acc: 0.9966 - val_loss: 0.1360 - val_acc: 1.0000\n",
      "Epoch 13/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 0.0733 - acc: 0.9989 - val_loss: 0.1288 - val_acc: 1.0000\n",
      "Epoch 14/150\n",
      "891/891 [==============================] - 1s 570us/step - loss: 0.0651 - acc: 0.9978 - val_loss: 0.1236 - val_acc: 1.0000\n",
      "Epoch 15/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0558 - acc: 1.0000 - val_loss: 0.1162 - val_acc: 1.0000\n",
      "Epoch 16/150\n",
      "891/891 [==============================] - 1s 580us/step - loss: 0.0535 - acc: 0.9978 - val_loss: 0.1108 - val_acc: 1.0000\n",
      "Epoch 17/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0456 - acc: 0.9989 - val_loss: 0.1059 - val_acc: 1.0000\n",
      "Epoch 18/150\n",
      "891/891 [==============================] - 1s 585us/step - loss: 0.0451 - acc: 1.0000 - val_loss: 0.0983 - val_acc: 1.0000\n",
      "Epoch 19/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0421 - acc: 0.9989 - val_loss: 0.0928 - val_acc: 1.0000\n",
      "Epoch 20/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 0.0399 - acc: 0.9989 - val_loss: 0.0893 - val_acc: 1.0000\n",
      "Epoch 21/150\n",
      "891/891 [==============================] - 1s 584us/step - loss: 0.0379 - acc: 1.0000 - val_loss: 0.0888 - val_acc: 1.0000\n",
      "Epoch 22/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0339 - acc: 1.0000 - val_loss: 0.0833 - val_acc: 1.0000\n",
      "Epoch 23/150\n",
      "891/891 [==============================] - 1s 595us/step - loss: 0.0339 - acc: 0.9989 - val_loss: 0.0813 - val_acc: 1.0000\n",
      "Epoch 24/150\n",
      "891/891 [==============================] - 1s 598us/step - loss: 0.0332 - acc: 0.9989 - val_loss: 0.0794 - val_acc: 1.0000\n",
      "Epoch 25/150\n",
      "891/891 [==============================] - 1s 585us/step - loss: 0.0297 - acc: 1.0000 - val_loss: 0.0751 - val_acc: 1.0000\n",
      "Epoch 26/150\n",
      "891/891 [==============================] - 1s 587us/step - loss: 0.0264 - acc: 1.0000 - val_loss: 0.0744 - val_acc: 1.0000\n",
      "Epoch 27/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0269 - acc: 1.0000 - val_loss: 0.0708 - val_acc: 1.0000\n",
      "Epoch 28/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 0.0256 - acc: 1.0000 - val_loss: 0.0691 - val_acc: 1.0000\n",
      "Epoch 29/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0237 - acc: 1.0000 - val_loss: 0.0681 - val_acc: 1.0000\n",
      "Epoch 30/150\n",
      "891/891 [==============================] - ETA: 0s - loss: 0.0226 - acc: 1.000 - 1s 572us/step - loss: 0.0241 - acc: 0.9989 - val_loss: 0.0656 - val_acc: 1.0000\n",
      "Epoch 31/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.0637 - val_acc: 1.0000\n",
      "Epoch 32/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.0642 - val_acc: 1.0000\n",
      "Epoch 33/150\n",
      "891/891 [==============================] - 1s 585us/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.0643 - val_acc: 1.0000\n",
      "Epoch 34/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 0.0632 - val_acc: 1.0000\n",
      "Epoch 35/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.0612 - val_acc: 1.0000\n",
      "Epoch 36/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.0578 - val_acc: 1.0000\n",
      "Epoch 37/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.0557 - val_acc: 1.0000\n",
      "Epoch 38/150\n",
      "891/891 [==============================] - 1s 586us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.0551 - val_acc: 1.0000\n",
      "Epoch 39/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.0547 - val_acc: 1.0000\n",
      "Epoch 40/150\n",
      "891/891 [==============================] - 1s 580us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.0542 - val_acc: 1.0000\n",
      "Epoch 41/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.0534 - val_acc: 1.0000\n",
      "Epoch 42/150\n",
      "891/891 [==============================] - 1s 581us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.0516 - val_acc: 1.0000\n",
      "Epoch 43/150\n",
      "891/891 [==============================] - 1s 577us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.0502 - val_acc: 1.0000\n",
      "Epoch 44/150\n",
      "891/891 [==============================] - 1s 604us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0491 - val_acc: 1.0000\n",
      "Epoch 45/150\n",
      "891/891 [==============================] - 1s 586us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.0481 - val_acc: 1.0000\n",
      "Epoch 46/150\n",
      "891/891 [==============================] - 1s 625us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.0473 - val_acc: 1.0000\n",
      "Epoch 47/150\n",
      "891/891 [==============================] - 1s 596us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.0467 - val_acc: 1.0000\n",
      "Epoch 48/150\n",
      "891/891 [==============================] - 1s 596us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0466 - val_acc: 1.0000\n",
      "Epoch 49/150\n",
      "891/891 [==============================] - 1s 593us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0464 - val_acc: 1.0000\n",
      "Epoch 50/150\n",
      "891/891 [==============================] - 1s 604us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.0452 - val_acc: 1.0000\n",
      "Epoch 51/150\n",
      "891/891 [==============================] - 1s 592us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0448 - val_acc: 1.0000\n",
      "Epoch 52/150\n",
      "891/891 [==============================] - 1s 599us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0450 - val_acc: 1.0000\n",
      "Epoch 53/150\n",
      "891/891 [==============================] - 1s 593us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0448 - val_acc: 1.0000\n",
      "Epoch 54/150\n",
      "891/891 [==============================] - 1s 587us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0441 - val_acc: 1.0000\n",
      "Epoch 55/150\n",
      "891/891 [==============================] - 1s 603us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0427 - val_acc: 1.0000\n",
      "Epoch 56/150\n",
      "891/891 [==============================] - 1s 600us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0423 - val_acc: 1.0000\n",
      "Epoch 57/150\n",
      "891/891 [==============================] - ETA: 0s - loss: 0.0090 - acc: 1.000 - 1s 594us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0426 - val_acc: 1.0000\n",
      "Epoch 58/150\n",
      "891/891 [==============================] - 1s 613us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0416 - val_acc: 1.0000\n",
      "Epoch 59/150\n",
      "891/891 [==============================] - 1s 610us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0404 - val_acc: 1.0000\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 1s 592us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0395 - val_acc: 1.0000\n",
      "Epoch 61/150\n",
      "891/891 [==============================] - 1s 598us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0398 - val_acc: 1.0000\n",
      "Epoch 62/150\n",
      "891/891 [==============================] - 1s 607us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 1.0000\n",
      "Epoch 63/150\n",
      "891/891 [==============================] - 1s 595us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 1.0000\n",
      "Epoch 64/150\n",
      "891/891 [==============================] - 1s 601us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 1.0000\n",
      "Epoch 65/150\n",
      "891/891 [==============================] - 1s 595us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0384 - val_acc: 1.0000\n",
      "Epoch 66/150\n",
      "891/891 [==============================] - 1s 603us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0379 - val_acc: 1.0000\n",
      "Epoch 67/150\n",
      "891/891 [==============================] - 1s 608us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 1.0000\n",
      "Epoch 68/150\n",
      "891/891 [==============================] - 1s 607us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0359 - val_acc: 1.0000\n",
      "Epoch 69/150\n",
      "891/891 [==============================] - 1s 597us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0356 - val_acc: 1.0000\n",
      "Epoch 70/150\n",
      "891/891 [==============================] - 1s 598us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0357 - val_acc: 1.0000\n",
      "Epoch 71/150\n",
      "891/891 [==============================] - 1s 598us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0362 - val_acc: 1.0000\n",
      "Epoch 72/150\n",
      "891/891 [==============================] - 1s 593us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0360 - val_acc: 1.0000\n",
      "Epoch 73/150\n",
      "891/891 [==============================] - 1s 594us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0359 - val_acc: 1.0000\n",
      "Epoch 74/150\n",
      "891/891 [==============================] - 1s 601us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0360 - val_acc: 1.0000\n",
      "Epoch 75/150\n",
      "891/891 [==============================] - 1s 606us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0360 - val_acc: 1.0000\n",
      "Epoch 76/150\n",
      "891/891 [==============================] - 1s 601us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0349 - val_acc: 1.0000\n",
      "Epoch 77/150\n",
      "891/891 [==============================] - 1s 592us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 1.0000\n",
      "Epoch 78/150\n",
      "891/891 [==============================] - 1s 602us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0346 - val_acc: 1.0000\n",
      "Epoch 79/150\n",
      "891/891 [==============================] - 1s 622us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 1.0000\n",
      "Epoch 80/150\n",
      "891/891 [==============================] - 1s 588us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0337 - val_acc: 1.0000\n",
      "Epoch 81/150\n",
      "891/891 [==============================] - 1s 601us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0332 - val_acc: 1.0000\n",
      "Epoch 82/150\n",
      "891/891 [==============================] - 1s 592us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0333 - val_acc: 1.0000\n",
      "Epoch 83/150\n",
      "891/891 [==============================] - 1s 600us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0333 - val_acc: 1.0000\n",
      "Epoch 84/150\n",
      "891/891 [==============================] - 1s 591us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0327 - val_acc: 1.0000\n",
      "Epoch 85/150\n",
      "891/891 [==============================] - 1s 594us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0326 - val_acc: 1.0000\n",
      "Epoch 86/150\n",
      "891/891 [==============================] - 1s 588us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 1.0000\n",
      "Epoch 87/150\n",
      "891/891 [==============================] - 1s 608us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0310 - val_acc: 1.0000\n",
      "Epoch 88/150\n",
      "891/891 [==============================] - 1s 587us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0304 - val_acc: 1.0000\n",
      "Epoch 89/150\n",
      "891/891 [==============================] - 1s 611us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0301 - val_acc: 1.0000\n",
      "Epoch 90/150\n",
      "891/891 [==============================] - 1s 593us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0299 - val_acc: 1.0000\n",
      "Epoch 91/150\n",
      "891/891 [==============================] - 1s 587us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0294 - val_acc: 1.0000\n",
      "Epoch 92/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0290 - val_acc: 1.0000\n",
      "Epoch 93/150\n",
      "891/891 [==============================] - 1s 593us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0289 - val_acc: 1.0000\n",
      "Epoch 94/150\n",
      "891/891 [==============================] - 1s 590us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0288 - val_acc: 1.0000\n",
      "Epoch 95/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0287 - val_acc: 1.0000\n",
      "Epoch 96/150\n",
      "891/891 [==============================] - 1s 607us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 1.0000\n",
      "Epoch 97/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0283 - val_acc: 1.0000\n",
      "Epoch 98/150\n",
      "891/891 [==============================] - 1s 584us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0287 - val_acc: 1.0000\n",
      "Epoch 99/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0288 - val_acc: 1.0000\n",
      "Epoch 100/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0286 - val_acc: 1.0000\n",
      "Epoch 101/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0283 - val_acc: 1.0000\n",
      "Epoch 102/150\n",
      "891/891 [==============================] - 1s 588us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 1.0000\n",
      "Epoch 103/150\n",
      "891/891 [==============================] - 1s 586us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0276 - val_acc: 1.0000\n",
      "Epoch 104/150\n",
      "891/891 [==============================] - 1s 582us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0274 - val_acc: 1.0000\n",
      "Epoch 105/150\n",
      "891/891 [==============================] - 1s 570us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 1.0000\n",
      "Epoch 106/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0270 - val_acc: 1.0000\n",
      "Epoch 107/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0265 - val_acc: 1.0000\n",
      "Epoch 108/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0264 - val_acc: 1.0000\n",
      "Epoch 109/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0261 - val_acc: 1.0000\n",
      "Epoch 110/150\n",
      "891/891 [==============================] - 1s 577us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0258 - val_acc: 1.0000\n",
      "Epoch 111/150\n",
      "891/891 [==============================] - 1s 565us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0257 - val_acc: 1.0000\n",
      "Epoch 112/150\n",
      "891/891 [==============================] - 1s 585us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0259 - val_acc: 1.0000\n",
      "Epoch 113/150\n",
      "891/891 [==============================] - 1s 581us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0258 - val_acc: 1.0000\n",
      "Epoch 114/150\n",
      "891/891 [==============================] - 1s 605us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0256 - val_acc: 1.0000\n",
      "Epoch 115/150\n",
      "891/891 [==============================] - 1s 587us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0257 - val_acc: 1.0000\n",
      "Epoch 116/150\n",
      "891/891 [==============================] - 1s 600us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0257 - val_acc: 1.0000\n",
      "Epoch 117/150\n",
      "891/891 [==============================] - 1s 581us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0255 - val_acc: 1.0000\n",
      "Epoch 118/150\n",
      "891/891 [==============================] - 1s 598us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0255 - val_acc: 1.0000\n",
      "Epoch 119/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0252 - val_acc: 1.0000\n",
      "Epoch 120/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 1s 580us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0245 - val_acc: 1.0000\n",
      "Epoch 121/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "Epoch 122/150\n",
      "891/891 [==============================] - 1s 568us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 1.0000\n",
      "Epoch 123/150\n",
      "891/891 [==============================] - 1s 590us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 1.0000\n",
      "Epoch 124/150\n",
      "891/891 [==============================] - 1s 564us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 125/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "Epoch 126/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0246 - val_acc: 1.0000\n",
      "Epoch 127/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0244 - val_acc: 1.0000\n",
      "Epoch 128/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 129/150\n",
      "891/891 [==============================] - 1s 570us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 1.0000\n",
      "Epoch 130/150\n",
      "891/891 [==============================] - 1s 586us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 1.0000\n",
      "Epoch 131/150\n",
      "891/891 [==============================] - 1s 570us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 1.0000\n",
      "Epoch 132/150\n",
      "891/891 [==============================] - 1s 593us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 1.0000\n",
      "Epoch 133/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 1.0000\n",
      "Epoch 134/150\n",
      "891/891 [==============================] - 1s 592us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 1.0000\n",
      "Epoch 135/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 1.0000\n",
      "Epoch 136/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0224 - val_acc: 1.0000\n",
      "Epoch 137/150\n",
      "891/891 [==============================] - 1s 584us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 1.0000\n",
      "Epoch 138/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 1.0000\n",
      "Epoch 139/150\n",
      "891/891 [==============================] - 1s 584us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 1.0000\n",
      "Epoch 140/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0216 - val_acc: 1.0000\n",
      "Epoch 141/150\n",
      "891/891 [==============================] - 1s 590us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 1.0000\n",
      "Epoch 142/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0221 - val_acc: 1.0000\n",
      "Epoch 143/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 1.0000\n",
      "Epoch 144/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 1.0000\n",
      "Epoch 145/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 1.0000\n",
      "Epoch 146/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0224 - val_acc: 1.0000\n",
      "Epoch 147/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0223 - val_acc: 1.0000\n",
      "Epoch 148/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 1.0000\n",
      "Epoch 149/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 1.0000\n",
      "Epoch 150/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x148ca5c6d68>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "#model2.fit(train_x_2, train_y_2, epochs = 100, verbose=1, validation_data=(validate_x_2, validate_y_2), callbacks=[history2])\n",
    "model2.fit(x, y, nb_epoch=150, batch_size=100, verbose=1, callbacks=[history2], validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lane0\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 891 samples, validate on 99 samples\n",
      "Epoch 1/150\n",
      "891/891 [==============================] - 1s 2ms/step - loss: 4.2526 - acc: 0.1818 - val_loss: 3.0030 - val_acc: 0.5758\n",
      "Epoch 2/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 2.3110 - acc: 0.6622 - val_loss: 1.8026 - val_acc: 0.8081\n",
      "Epoch 3/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 1.2371 - acc: 0.8608 - val_loss: 1.0516 - val_acc: 0.9091\n",
      "Epoch 4/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.6945 - acc: 0.9416 - val_loss: 0.6117 - val_acc: 0.9495\n",
      "Epoch 5/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.4154 - acc: 0.9630 - val_loss: 0.4080 - val_acc: 0.9798\n",
      "Epoch 6/150\n",
      "891/891 [==============================] - 1s 586us/step - loss: 0.2736 - acc: 0.9865 - val_loss: 0.3063 - val_acc: 0.9899\n",
      "Epoch 7/150\n",
      "891/891 [==============================] - 1s 564us/step - loss: 0.2002 - acc: 0.9921 - val_loss: 0.2345 - val_acc: 0.9899\n",
      "Epoch 8/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.1598 - acc: 0.9944 - val_loss: 0.1937 - val_acc: 1.0000\n",
      "Epoch 9/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.1241 - acc: 0.9989 - val_loss: 0.1695 - val_acc: 1.0000\n",
      "Epoch 10/150\n",
      "891/891 [==============================] - 1s 599us/step - loss: 0.1060 - acc: 0.9944 - val_loss: 0.1567 - val_acc: 1.0000\n",
      "Epoch 11/150\n",
      "891/891 [==============================] - 1s 581us/step - loss: 0.0913 - acc: 0.9978 - val_loss: 0.1420 - val_acc: 1.0000\n",
      "Epoch 12/150\n",
      "891/891 [==============================] - 1s 587us/step - loss: 0.0773 - acc: 0.9989 - val_loss: 0.1250 - val_acc: 1.0000\n",
      "Epoch 13/150\n",
      "891/891 [==============================] - 1s 604us/step - loss: 0.0722 - acc: 0.9966 - val_loss: 0.1150 - val_acc: 1.0000\n",
      "Epoch 14/150\n",
      "891/891 [==============================] - 1s 597us/step - loss: 0.0622 - acc: 1.0000 - val_loss: 0.1093 - val_acc: 1.0000\n",
      "Epoch 15/150\n",
      "891/891 [==============================] - 1s 588us/step - loss: 0.0537 - acc: 1.0000 - val_loss: 0.1020 - val_acc: 1.0000\n",
      "Epoch 16/150\n",
      "891/891 [==============================] - 1s 599us/step - loss: 0.0510 - acc: 0.9989 - val_loss: 0.0974 - val_acc: 1.0000\n",
      "Epoch 17/150\n",
      "891/891 [==============================] - 1s 577us/step - loss: 0.0483 - acc: 0.9989 - val_loss: 0.0931 - val_acc: 1.0000\n",
      "Epoch 18/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0477 - acc: 0.9955 - val_loss: 0.0898 - val_acc: 1.0000\n",
      "Epoch 19/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 0.0391 - acc: 1.0000 - val_loss: 0.0867 - val_acc: 1.0000\n",
      "Epoch 20/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0383 - acc: 1.0000 - val_loss: 0.0810 - val_acc: 1.0000\n",
      "Epoch 21/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 0.0363 - acc: 1.0000 - val_loss: 0.0781 - val_acc: 1.0000\n",
      "Epoch 22/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 0.0358 - acc: 1.0000 - val_loss: 0.0735 - val_acc: 1.0000\n",
      "Epoch 23/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0319 - acc: 1.0000 - val_loss: 0.0715 - val_acc: 1.0000\n",
      "Epoch 24/150\n",
      "891/891 [==============================] - ETA: 0s - loss: 0.0313 - acc: 1.000 - 1s 583us/step - loss: 0.0312 - acc: 1.0000 - val_loss: 0.0702 - val_acc: 1.0000\n",
      "Epoch 25/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0275 - acc: 1.0000 - val_loss: 0.0681 - val_acc: 1.0000\n",
      "Epoch 26/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 0.0279 - acc: 1.0000 - val_loss: 0.0647 - val_acc: 1.0000\n",
      "Epoch 27/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0260 - acc: 1.0000 - val_loss: 0.0629 - val_acc: 1.0000\n",
      "Epoch 28/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0239 - acc: 0.9989 - val_loss: 0.0611 - val_acc: 1.0000\n",
      "Epoch 29/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0236 - acc: 1.0000 - val_loss: 0.0597 - val_acc: 1.0000\n",
      "Epoch 30/150\n",
      "891/891 [==============================] - 1s 566us/step - loss: 0.0226 - acc: 1.0000 - val_loss: 0.0589 - val_acc: 1.0000\n",
      "Epoch 31/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.0574 - val_acc: 1.0000\n",
      "Epoch 32/150\n",
      "891/891 [==============================] - 1s 622us/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.0549 - val_acc: 1.0000\n",
      "Epoch 33/150\n",
      "891/891 [==============================] - 1s 593us/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.0527 - val_acc: 1.0000\n",
      "Epoch 34/150\n",
      "891/891 [==============================] - 1s 582us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.0514 - val_acc: 1.0000\n",
      "Epoch 35/150\n",
      "891/891 [==============================] - 1s 602us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.0508 - val_acc: 1.0000\n",
      "Epoch 36/150\n",
      "891/891 [==============================] - 1s 586us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.0503 - val_acc: 1.0000\n",
      "Epoch 37/150\n",
      "891/891 [==============================] - 1s 597us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.0493 - val_acc: 1.0000\n",
      "Epoch 38/150\n",
      "891/891 [==============================] - 1s 592us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.0478 - val_acc: 1.0000\n",
      "Epoch 39/150\n",
      "891/891 [==============================] - 1s 582us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.0474 - val_acc: 1.0000\n",
      "Epoch 40/150\n",
      "891/891 [==============================] - 1s 580us/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.0499 - val_acc: 1.0000\n",
      "Epoch 41/150\n",
      "891/891 [==============================] - 1s 585us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.0488 - val_acc: 1.0000\n",
      "Epoch 42/150\n",
      "891/891 [==============================] - 1s 580us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0470 - val_acc: 1.0000\n",
      "Epoch 43/150\n",
      "891/891 [==============================] - 1s 588us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.0447 - val_acc: 1.0000\n",
      "Epoch 44/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.0423 - val_acc: 1.0000\n",
      "Epoch 45/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.0410 - val_acc: 1.0000\n",
      "Epoch 46/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.0407 - val_acc: 1.0000\n",
      "Epoch 47/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0409 - val_acc: 1.0000\n",
      "Epoch 48/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.0404 - val_acc: 1.0000\n",
      "Epoch 49/150\n",
      "891/891 [==============================] - 1s 566us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0389 - val_acc: 1.0000\n",
      "Epoch 50/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0382 - val_acc: 1.0000\n",
      "Epoch 51/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.0376 - val_acc: 1.0000\n",
      "Epoch 52/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0370 - val_acc: 1.0000\n",
      "Epoch 53/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0371 - val_acc: 1.0000\n",
      "Epoch 54/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0368 - val_acc: 1.0000\n",
      "Epoch 55/150\n",
      "891/891 [==============================] - 1s 590us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0360 - val_acc: 1.0000\n",
      "Epoch 56/150\n",
      "891/891 [==============================] - 1s 568us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0354 - val_acc: 1.0000\n",
      "Epoch 57/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0352 - val_acc: 1.0000\n",
      "Epoch 58/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 1.0000\n",
      "Epoch 59/150\n",
      "891/891 [==============================] - 1s 566us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0336 - val_acc: 1.0000\n",
      "Epoch 60/150\n",
      "891/891 [==============================] - 1s 582us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0333 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 1.0000\n",
      "Epoch 62/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0337 - val_acc: 1.0000\n",
      "Epoch 63/150\n",
      "891/891 [==============================] - 1s 585us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0331 - val_acc: 1.0000\n",
      "Epoch 64/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0326 - val_acc: 1.0000\n",
      "Epoch 65/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0322 - val_acc: 1.0000\n",
      "Epoch 66/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0320 - val_acc: 1.0000\n",
      "Epoch 67/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0318 - val_acc: 1.0000\n",
      "Epoch 68/150\n",
      "891/891 [==============================] - 1s 567us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0313 - val_acc: 1.0000\n",
      "Epoch 69/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0310 - val_acc: 1.0000\n",
      "Epoch 70/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0301 - val_acc: 1.0000\n",
      "Epoch 71/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 1.0000\n",
      "Epoch 72/150\n",
      "891/891 [==============================] - 1s 564us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 1.0000\n",
      "Epoch 73/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0289 - val_acc: 1.0000\n",
      "Epoch 74/150\n",
      "891/891 [==============================] - 1s 581us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0286 - val_acc: 1.0000\n",
      "Epoch 75/150\n",
      "891/891 [==============================] - 1s 564us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 1.0000\n",
      "Epoch 76/150\n",
      "891/891 [==============================] - ETA: 0s - loss: 0.0063 - acc: 1.000 - 1s 569us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0275 - val_acc: 1.0000\n",
      "Epoch 77/150\n",
      "891/891 [==============================] - 1s 570us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0273 - val_acc: 1.0000\n",
      "Epoch 78/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0273 - val_acc: 1.0000\n",
      "Epoch 79/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0273 - val_acc: 1.0000\n",
      "Epoch 80/150\n",
      "891/891 [==============================] - 1s 564us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0269 - val_acc: 1.0000\n",
      "Epoch 81/150\n",
      "891/891 [==============================] - 1s 587us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0266 - val_acc: 1.0000\n",
      "Epoch 82/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0260 - val_acc: 1.0000\n",
      "Epoch 83/150\n",
      "891/891 [==============================] - 1s 581us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0257 - val_acc: 1.0000\n",
      "Epoch 84/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0253 - val_acc: 1.0000\n",
      "Epoch 85/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0252 - val_acc: 1.0000\n",
      "Epoch 86/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0254 - val_acc: 1.0000\n",
      "Epoch 87/150\n",
      "891/891 [==============================] - 1s 588us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0256 - val_acc: 1.0000\n",
      "Epoch 88/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0257 - val_acc: 1.0000\n",
      "Epoch 89/150\n",
      "891/891 [==============================] - 1s 581us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0253 - val_acc: 1.0000\n",
      "Epoch 90/150\n",
      "891/891 [==============================] - 1s 587us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0252 - val_acc: 1.0000\n",
      "Epoch 91/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 1.0000\n",
      "Epoch 92/150\n",
      "891/891 [==============================] - 1s 577us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 1.0000\n",
      "Epoch 93/150\n",
      "891/891 [==============================] - 1s 584us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0246 - val_acc: 1.0000\n",
      "Epoch 94/150\n",
      "891/891 [==============================] - 1s 580us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0240 - val_acc: 1.0000\n",
      "Epoch 95/150\n",
      "891/891 [==============================] - 1s 570us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 1.0000\n",
      "Epoch 96/150\n",
      "891/891 [==============================] - 1s 588us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 1.0000\n",
      "Epoch 97/150\n",
      "891/891 [==============================] - 1s 611us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 1.0000\n",
      "Epoch 98/150\n",
      "891/891 [==============================] - 1s 604us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 1.0000\n",
      "Epoch 99/150\n",
      "891/891 [==============================] - 1s 568us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 1.0000\n",
      "Epoch 100/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0227 - val_acc: 1.0000\n",
      "Epoch 101/150\n",
      "891/891 [==============================] - 1s 588us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 1.0000\n",
      "Epoch 102/150\n",
      "891/891 [==============================] - 1s 601us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 1.0000\n",
      "Epoch 103/150\n",
      "891/891 [==============================] - ETA: 0s - loss: 0.0040 - acc: 1.000 - 1s 587us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0221 - val_acc: 1.0000\n",
      "Epoch 104/150\n",
      "891/891 [==============================] - 1s 580us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 1.0000\n",
      "Epoch 105/150\n",
      "891/891 [==============================] - 1s 568us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0217 - val_acc: 1.0000\n",
      "Epoch 106/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0216 - val_acc: 1.0000\n",
      "Epoch 107/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 108/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 1.0000\n",
      "Epoch 109/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 1.0000\n",
      "Epoch 110/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 1.0000\n",
      "Epoch 111/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 1.0000\n",
      "Epoch 112/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 1.0000\n",
      "Epoch 113/150\n",
      "891/891 [==============================] - 1s 602us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 1.0000\n",
      "Epoch 114/150\n",
      "891/891 [==============================] - 1s 582us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 1.0000\n",
      "Epoch 115/150\n",
      "891/891 [==============================] - 1s 581us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 1.0000\n",
      "Epoch 116/150\n",
      "891/891 [==============================] - 1s 590us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
      "Epoch 117/150\n",
      "891/891 [==============================] - 1s 587us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
      "Epoch 118/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
      "Epoch 119/150\n",
      "891/891 [==============================] - 1s 568us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 1.0000\n",
      "Epoch 120/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 1s 571us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 1.0000\n",
      "Epoch 121/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
      "Epoch 122/150\n",
      "891/891 [==============================] - 1s 584us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 1.0000\n",
      "Epoch 123/150\n",
      "891/891 [==============================] - 1s 595us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 1.0000\n",
      "Epoch 124/150\n",
      "891/891 [==============================] - 1s 627us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 125/150\n",
      "891/891 [==============================] - 1s 597us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
      "Epoch 126/150\n",
      "891/891 [==============================] - 1s 592us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 1.0000\n",
      "Epoch 127/150\n",
      "891/891 [==============================] - 1s 588us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 128/150\n",
      "891/891 [==============================] - 1s 604us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 1.0000\n",
      "Epoch 129/150\n",
      "891/891 [==============================] - 1s 594us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 130/150\n",
      "891/891 [==============================] - 1s 588us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 131/150\n",
      "891/891 [==============================] - 1s 585us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 132/150\n",
      "891/891 [==============================] - 1s 589us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0175 - val_acc: 1.0000\n",
      "Epoch 133/150\n",
      "891/891 [==============================] - 1s 588us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0175 - val_acc: 1.0000\n",
      "Epoch 134/150\n",
      "891/891 [==============================] - 1s 589us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0176 - val_acc: 1.0000\n",
      "Epoch 135/150\n",
      "891/891 [==============================] - 1s 580us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0175 - val_acc: 1.0000\n",
      "Epoch 136/150\n",
      "891/891 [==============================] - 1s 602us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0176 - val_acc: 1.0000\n",
      "Epoch 137/150\n",
      "891/891 [==============================] - 1s 592us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0175 - val_acc: 1.0000\n",
      "Epoch 138/150\n",
      "891/891 [==============================] - 1s 595us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 1.0000\n",
      "Epoch 139/150\n",
      "891/891 [==============================] - 1s 599us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
      "Epoch 140/150\n",
      "891/891 [==============================] - 1s 588us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
      "Epoch 141/150\n",
      "891/891 [==============================] - 1s 588us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 1.0000\n",
      "Epoch 142/150\n",
      "891/891 [==============================] - 1s 600us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 1.0000\n",
      "Epoch 143/150\n",
      "891/891 [==============================] - 1s 623us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0166 - val_acc: 1.0000\n",
      "Epoch 144/150\n",
      "891/891 [==============================] - 1s 589us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 145/150\n",
      "891/891 [==============================] - 1s 598us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 146/150\n",
      "891/891 [==============================] - 1s 596us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 1.0000\n",
      "Epoch 147/150\n",
      "891/891 [==============================] - 1s 584us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 1.0000\n",
      "Epoch 148/150\n",
      "891/891 [==============================] - 1s 589us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 1.0000\n",
      "Epoch 149/150\n",
      "891/891 [==============================] - 1s 584us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 1.0000\n",
      "Epoch 150/150\n",
      "891/891 [==============================] - 1s 603us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0154 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x148cb9a5eb8>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "#model3.fit(train_x_3, train_y_3, epochs = 100, verbose=1, validation_data=(validate_x_3, validate_y_3), callbacks=[history3])\n",
    "model3.fit(x, y, nb_epoch=150, batch_size=100, verbose=1, callbacks=[history3], validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lane0\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 891 samples, validate on 99 samples\n",
      "Epoch 1/150\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 4.1871 - acc: 0.1762 - val_loss: 2.9654 - val_acc: 0.4949\n",
      "Epoch 2/150\n",
      "891/891 [==============================] - 1s 594us/step - loss: 2.2457 - acc: 0.6442 - val_loss: 1.6817 - val_acc: 0.8081\n",
      "Epoch 3/150\n",
      "891/891 [==============================] - 1s 599us/step - loss: 1.1922 - acc: 0.8889 - val_loss: 0.9628 - val_acc: 0.9596\n",
      "Epoch 4/150\n",
      "891/891 [==============================] - 1s 589us/step - loss: 0.6417 - acc: 0.9585 - val_loss: 0.5789 - val_acc: 0.9697\n",
      "Epoch 5/150\n",
      "891/891 [==============================] - 1s 602us/step - loss: 0.4015 - acc: 0.9697 - val_loss: 0.3839 - val_acc: 0.9798\n",
      "Epoch 6/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.2801 - acc: 0.9809 - val_loss: 0.2863 - val_acc: 1.0000\n",
      "Epoch 7/150\n",
      "891/891 [==============================] - 1s 613us/step - loss: 0.1950 - acc: 0.9955 - val_loss: 0.2366 - val_acc: 1.0000\n",
      "Epoch 8/150\n",
      "891/891 [==============================] - 1s 651us/step - loss: 0.1556 - acc: 0.9933 - val_loss: 0.1989 - val_acc: 1.0000\n",
      "Epoch 9/150\n",
      "891/891 [==============================] - 1s 640us/step - loss: 0.1203 - acc: 0.9966 - val_loss: 0.1696 - val_acc: 1.0000\n",
      "Epoch 10/150\n",
      "891/891 [==============================] - 1s 620us/step - loss: 0.1071 - acc: 0.9933 - val_loss: 0.1492 - val_acc: 1.0000\n",
      "Epoch 11/150\n",
      "891/891 [==============================] - 1s 604us/step - loss: 0.0934 - acc: 0.9966 - val_loss: 0.1378 - val_acc: 1.0000\n",
      "Epoch 12/150\n",
      "891/891 [==============================] - 1s 580us/step - loss: 0.0780 - acc: 0.9989 - val_loss: 0.1281 - val_acc: 1.0000\n",
      "Epoch 13/150\n",
      "891/891 [==============================] - 1s 636us/step - loss: 0.0739 - acc: 0.9989 - val_loss: 0.1200 - val_acc: 1.0000\n",
      "Epoch 14/150\n",
      "891/891 [==============================] - 1s 615us/step - loss: 0.0640 - acc: 1.0000 - val_loss: 0.1150 - val_acc: 1.0000\n",
      "Epoch 15/150\n",
      "891/891 [==============================] - 0s 557us/step - loss: 0.0549 - acc: 1.0000 - val_loss: 0.1054 - val_acc: 1.0000\n",
      "Epoch 16/150\n",
      "891/891 [==============================] - 1s 585us/step - loss: 0.0540 - acc: 0.9989 - val_loss: 0.0979 - val_acc: 1.0000\n",
      "Epoch 17/150\n",
      "891/891 [==============================] - 1s 590us/step - loss: 0.0510 - acc: 0.9978 - val_loss: 0.0985 - val_acc: 1.0000\n",
      "Epoch 18/150\n",
      "891/891 [==============================] - 1s 637us/step - loss: 0.0429 - acc: 0.9989 - val_loss: 0.0924 - val_acc: 1.0000\n",
      "Epoch 19/150\n",
      "891/891 [==============================] - 1s 584us/step - loss: 0.0407 - acc: 0.9989 - val_loss: 0.0847 - val_acc: 1.0000\n",
      "Epoch 20/150\n",
      "891/891 [==============================] - 1s 566us/step - loss: 0.0393 - acc: 1.0000 - val_loss: 0.0823 - val_acc: 1.0000\n",
      "Epoch 21/150\n",
      "891/891 [==============================] - 1s 585us/step - loss: 0.0354 - acc: 1.0000 - val_loss: 0.0785 - val_acc: 1.0000\n",
      "Epoch 22/150\n",
      "891/891 [==============================] - 1s 564us/step - loss: 0.0338 - acc: 0.9989 - val_loss: 0.0753 - val_acc: 1.0000\n",
      "Epoch 23/150\n",
      "891/891 [==============================] - 0s 560us/step - loss: 0.0312 - acc: 1.0000 - val_loss: 0.0735 - val_acc: 1.0000\n",
      "Epoch 24/150\n",
      "891/891 [==============================] - 1s 563us/step - loss: 0.0301 - acc: 1.0000 - val_loss: 0.0715 - val_acc: 1.0000\n",
      "Epoch 25/150\n",
      "891/891 [==============================] - 1s 570us/step - loss: 0.0285 - acc: 1.0000 - val_loss: 0.0710 - val_acc: 1.0000\n",
      "Epoch 26/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 0.0257 - acc: 1.0000 - val_loss: 0.0664 - val_acc: 1.0000\n",
      "Epoch 27/150\n",
      "891/891 [==============================] - 1s 593us/step - loss: 0.0256 - acc: 0.9989 - val_loss: 0.0646 - val_acc: 1.0000\n",
      "Epoch 28/150\n",
      "891/891 [==============================] - 1s 584us/step - loss: 0.0219 - acc: 1.0000 - val_loss: 0.0632 - val_acc: 1.0000\n",
      "Epoch 29/150\n",
      "891/891 [==============================] - 1s 584us/step - loss: 0.0221 - acc: 1.0000 - val_loss: 0.0629 - val_acc: 1.0000\n",
      "Epoch 30/150\n",
      "891/891 [==============================] - 1s 588us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.0623 - val_acc: 1.0000\n",
      "Epoch 31/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.0615 - val_acc: 1.0000\n",
      "Epoch 32/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.0590 - val_acc: 1.0000\n",
      "Epoch 33/150\n",
      "891/891 [==============================] - 1s 590us/step - loss: 0.0195 - acc: 1.0000 - val_loss: 0.0573 - val_acc: 1.0000\n",
      "Epoch 34/150\n",
      "891/891 [==============================] - 1s 588us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.0575 - val_acc: 1.0000\n",
      "Epoch 35/150\n",
      "891/891 [==============================] - 0s 551us/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.0538 - val_acc: 1.0000\n",
      "Epoch 36/150\n",
      "891/891 [==============================] - 1s 587us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.0514 - val_acc: 1.0000\n",
      "Epoch 37/150\n",
      "891/891 [==============================] - 1s 576us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.0507 - val_acc: 1.0000\n",
      "Epoch 38/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.0511 - val_acc: 1.0000\n",
      "Epoch 39/150\n",
      "891/891 [==============================] - 1s 592us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.0499 - val_acc: 1.0000\n",
      "Epoch 40/150\n",
      "891/891 [==============================] - 1s 565us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.0491 - val_acc: 1.0000\n",
      "Epoch 41/150\n",
      "891/891 [==============================] - 1s 590us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0488 - val_acc: 1.0000\n",
      "Epoch 42/150\n",
      "891/891 [==============================] - 1s 585us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.0497 - val_acc: 1.0000\n",
      "Epoch 43/150\n",
      "891/891 [==============================] - 1s 598us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.0488 - val_acc: 1.0000\n",
      "Epoch 44/150\n",
      "891/891 [==============================] - 1s 585us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.0463 - val_acc: 1.0000\n",
      "Epoch 45/150\n",
      "891/891 [==============================] - 1s 609us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.0452 - val_acc: 1.0000\n",
      "Epoch 46/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0445 - val_acc: 1.0000\n",
      "Epoch 47/150\n",
      "891/891 [==============================] - 1s 608us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.0445 - val_acc: 1.0000\n",
      "Epoch 48/150\n",
      "891/891 [==============================] - 1s 581us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.0443 - val_acc: 1.0000\n",
      "Epoch 49/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.0435 - val_acc: 1.0000\n",
      "Epoch 50/150\n",
      "891/891 [==============================] - 1s 599us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0433 - val_acc: 1.0000\n",
      "Epoch 51/150\n",
      "891/891 [==============================] - 1s 621us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0429 - val_acc: 1.0000\n",
      "Epoch 52/150\n",
      "891/891 [==============================] - 1s 578us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0421 - val_acc: 1.0000\n",
      "Epoch 53/150\n",
      "891/891 [==============================] - ETA: 0s - loss: 0.0101 - acc: 1.000 - 1s 581us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0418 - val_acc: 1.0000\n",
      "Epoch 54/150\n",
      "891/891 [==============================] - 1s 589us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0406 - val_acc: 1.0000\n",
      "Epoch 55/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0394 - val_acc: 1.0000\n",
      "Epoch 56/150\n",
      "891/891 [==============================] - 1s 597us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0381 - val_acc: 1.0000\n",
      "Epoch 57/150\n",
      "891/891 [==============================] - 1s 603us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0373 - val_acc: 1.0000\n",
      "Epoch 58/150\n",
      "891/891 [==============================] - 1s 599us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0370 - val_acc: 1.0000\n",
      "Epoch 59/150\n",
      "891/891 [==============================] - 1s 623us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0371 - val_acc: 1.0000\n",
      "Epoch 60/150\n",
      "891/891 [==============================] - 1s 595us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0373 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150\n",
      "891/891 [==============================] - 0s 540us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0376 - val_acc: 1.0000\n",
      "Epoch 62/150\n",
      "891/891 [==============================] - 0s 559us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 1.0000\n",
      "Epoch 63/150\n",
      "891/891 [==============================] - 1s 589us/step - loss: 0.0091 - acc: 0.9989 - val_loss: 0.0368 - val_acc: 1.0000\n",
      "Epoch 64/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0385 - val_acc: 1.0000\n",
      "Epoch 65/150\n",
      "891/891 [==============================] - 0s 557us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0375 - val_acc: 1.0000\n",
      "Epoch 66/150\n",
      "891/891 [==============================] - 0s 551us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0359 - val_acc: 1.0000\n",
      "Epoch 67/150\n",
      "891/891 [==============================] - 0s 536us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 1.0000\n",
      "Epoch 68/150\n",
      "891/891 [==============================] - 0s 532us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0327 - val_acc: 1.0000\n",
      "Epoch 69/150\n",
      "891/891 [==============================] - 0s 541us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0327 - val_acc: 1.0000\n",
      "Epoch 70/150\n",
      "891/891 [==============================] - 0s 532us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0339 - val_acc: 1.0000\n",
      "Epoch 71/150\n",
      "891/891 [==============================] - 1s 580us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 1.0000\n",
      "Epoch 72/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 1.0000\n",
      "Epoch 73/150\n",
      "891/891 [==============================] - 1s 589us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0334 - val_acc: 1.0000\n",
      "Epoch 74/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0330 - val_acc: 1.0000\n",
      "Epoch 75/150\n",
      "891/891 [==============================] - 0s 551us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0329 - val_acc: 1.0000\n",
      "Epoch 76/150\n",
      "891/891 [==============================] - 1s 565us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0326 - val_acc: 1.0000\n",
      "Epoch 77/150\n",
      "891/891 [==============================] - 1s 563us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0322 - val_acc: 1.0000\n",
      "Epoch 78/150\n",
      "891/891 [==============================] - 0s 544us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0316 - val_acc: 1.0000\n",
      "Epoch 79/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0311 - val_acc: 1.0000\n",
      "Epoch 80/150\n",
      "891/891 [==============================] - 0s 555us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0311 - val_acc: 1.0000\n",
      "Epoch 81/150\n",
      "891/891 [==============================] - 0s 540us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0310 - val_acc: 1.0000\n",
      "Epoch 82/150\n",
      "891/891 [==============================] - 1s 564us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0309 - val_acc: 1.0000\n",
      "Epoch 83/150\n",
      "891/891 [==============================] - 0s 540us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0306 - val_acc: 1.0000\n",
      "Epoch 84/150\n",
      "891/891 [==============================] - 0s 546us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0299 - val_acc: 1.0000\n",
      "Epoch 85/150\n",
      "891/891 [==============================] - 0s 554us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0293 - val_acc: 1.0000\n",
      "Epoch 86/150\n",
      "891/891 [==============================] - 0s 545us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0289 - val_acc: 1.0000\n",
      "Epoch 87/150\n",
      "891/891 [==============================] - 1s 565us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0289 - val_acc: 1.0000\n",
      "Epoch 88/150\n",
      "891/891 [==============================] - 0s 548us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0287 - val_acc: 1.0000\n",
      "Epoch 89/150\n",
      "891/891 [==============================] - 0s 553us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0286 - val_acc: 1.0000\n",
      "Epoch 90/150\n",
      "891/891 [==============================] - 0s 551us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0284 - val_acc: 1.0000\n",
      "Epoch 91/150\n",
      "891/891 [==============================] - 0s 546us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 1.0000\n",
      "Epoch 92/150\n",
      "891/891 [==============================] - 0s 554us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0275 - val_acc: 1.0000\n",
      "Epoch 93/150\n",
      "891/891 [==============================] - 0s 551us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0268 - val_acc: 1.0000\n",
      "Epoch 94/150\n",
      "891/891 [==============================] - 0s 550us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0264 - val_acc: 1.0000\n",
      "Epoch 95/150\n",
      "891/891 [==============================] - 0s 550us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0264 - val_acc: 1.0000\n",
      "Epoch 96/150\n",
      "891/891 [==============================] - 0s 548us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0260 - val_acc: 1.0000\n",
      "Epoch 97/150\n",
      "891/891 [==============================] - 0s 561us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0257 - val_acc: 1.0000\n",
      "Epoch 98/150\n",
      "891/891 [==============================] - 0s 552us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0255 - val_acc: 1.0000\n",
      "Epoch 99/150\n",
      "891/891 [==============================] - 0s 550us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0254 - val_acc: 1.0000\n",
      "Epoch 100/150\n",
      "891/891 [==============================] - 0s 554us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0252 - val_acc: 1.0000\n",
      "Epoch 101/150\n",
      "891/891 [==============================] - 0s 556us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 1.0000\n",
      "Epoch 102/150\n",
      "891/891 [==============================] - 0s 554us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 1.0000\n",
      "Epoch 103/150\n",
      "891/891 [==============================] - 0s 554us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 1.0000\n",
      "Epoch 104/150\n",
      "891/891 [==============================] - 0s 552us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 1.0000\n",
      "Epoch 105/150\n",
      "891/891 [==============================] - 0s 546us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0254 - val_acc: 1.0000\n",
      "Epoch 106/150\n",
      "891/891 [==============================] - 0s 554us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0257 - val_acc: 1.0000\n",
      "Epoch 107/150\n",
      "891/891 [==============================] - 0s 560us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0256 - val_acc: 1.0000\n",
      "Epoch 108/150\n",
      "891/891 [==============================] - 0s 546us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0253 - val_acc: 1.0000\n",
      "Epoch 109/150\n",
      "891/891 [==============================] - 0s 554us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 1.0000\n",
      "Epoch 110/150\n",
      "891/891 [==============================] - 0s 554us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0240 - val_acc: 1.0000\n",
      "Epoch 111/150\n",
      "891/891 [==============================] - 0s 550us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 1.0000\n",
      "Epoch 112/150\n",
      "891/891 [==============================] - 0s 554us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 1.0000\n",
      "Epoch 113/150\n",
      "891/891 [==============================] - 0s 552us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 1.0000\n",
      "Epoch 114/150\n",
      "891/891 [==============================] - 0s 557us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 1.0000\n",
      "Epoch 115/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 1.0000\n",
      "Epoch 116/150\n",
      "891/891 [==============================] - 0s 552us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 1.0000\n",
      "Epoch 117/150\n",
      "891/891 [==============================] - 0s 547us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 1.0000\n",
      "Epoch 118/150\n",
      "891/891 [==============================] - 0s 554us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 1.0000\n",
      "Epoch 119/150\n",
      "891/891 [==============================] - 0s 561us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 1.0000\n",
      "Epoch 120/150\n",
      "891/891 [==============================] - 0s 561us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "Epoch 121/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 546us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0243 - val_acc: 1.0000\n",
      "Epoch 122/150\n",
      "891/891 [==============================] - 0s 552us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0240 - val_acc: 1.0000\n",
      "Epoch 123/150\n",
      "891/891 [==============================] - 0s 541us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 1.0000\n",
      "Epoch 124/150\n",
      "891/891 [==============================] - 0s 547us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 1.0000\n",
      "Epoch 125/150\n",
      "891/891 [==============================] - 0s 559us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 1.0000\n",
      "Epoch 126/150\n",
      "891/891 [==============================] - 0s 554us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 1.0000\n",
      "Epoch 127/150\n",
      "891/891 [==============================] - 0s 546us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 1.0000\n",
      "Epoch 128/150\n",
      "891/891 [==============================] - 0s 552us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 1.0000\n",
      "Epoch 129/150\n",
      "891/891 [==============================] - 0s 546us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0221 - val_acc: 1.0000\n",
      "Epoch 130/150\n",
      "891/891 [==============================] - 0s 543us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0217 - val_acc: 1.0000\n",
      "Epoch 131/150\n",
      "891/891 [==============================] - 0s 552us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0213 - val_acc: 1.0000\n",
      "Epoch 132/150\n",
      "891/891 [==============================] - 1s 565us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 133/150\n",
      "891/891 [==============================] - 0s 542us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 134/150\n",
      "891/891 [==============================] - 0s 543us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 1.0000\n",
      "Epoch 135/150\n",
      "891/891 [==============================] - 0s 551us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 1.0000\n",
      "Epoch 136/150\n",
      "891/891 [==============================] - 0s 556us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 1.0000\n",
      "Epoch 137/150\n",
      "891/891 [==============================] - 0s 554us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0211 - val_acc: 1.0000\n",
      "Epoch 138/150\n",
      "891/891 [==============================] - 0s 543us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0211 - val_acc: 1.0000\n",
      "Epoch 139/150\n",
      "891/891 [==============================] - 0s 556us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 1.0000\n",
      "Epoch 140/150\n",
      "891/891 [==============================] - 0s 553us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 1.0000\n",
      "Epoch 141/150\n",
      "891/891 [==============================] - 0s 547us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 1.0000\n",
      "Epoch 142/150\n",
      "891/891 [==============================] - 0s 554us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0203 - val_acc: 1.0000\n",
      "Epoch 143/150\n",
      "891/891 [==============================] - 0s 545us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0202 - val_acc: 1.0000\n",
      "Epoch 144/150\n",
      "891/891 [==============================] - 0s 561us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 1.0000\n",
      "Epoch 145/150\n",
      "891/891 [==============================] - 0s 556us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0202 - val_acc: 1.0000\n",
      "Epoch 146/150\n",
      "891/891 [==============================] - 0s 554us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 1.0000\n",
      "Epoch 147/150\n",
      "891/891 [==============================] - 0s 555us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0196 - val_acc: 1.0000\n",
      "Epoch 148/150\n",
      "891/891 [==============================] - 0s 544us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
      "Epoch 149/150\n",
      "891/891 [==============================] - 0s 550us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
      "Epoch 150/150\n",
      "891/891 [==============================] - 0s 560us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x148cb9a5cc0>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "#model4.fit(train_x_3, train_y_3, epochs = 100, verbose=1, validation_data=(validate_x_3, validate_y_3), callbacks=[history3])\n",
    "model4.fit(x, y, nb_epoch=150, batch_size=100, verbose=1, callbacks=[history4], validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lane0\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 891 samples, validate on 99 samples\n",
      "Epoch 1/150\n",
      "891/891 [==============================] - 1s 2ms/step - loss: 4.1215 - acc: 0.1661 - val_loss: 2.9632 - val_acc: 0.5051\n",
      "Epoch 2/150\n",
      "891/891 [==============================] - 0s 550us/step - loss: 2.2085 - acc: 0.6667 - val_loss: 1.7096 - val_acc: 0.8182\n",
      "Epoch 3/150\n",
      "891/891 [==============================] - 0s 560us/step - loss: 1.1491 - acc: 0.8934 - val_loss: 0.9898 - val_acc: 0.9293\n",
      "Epoch 4/150\n",
      "891/891 [==============================] - 0s 553us/step - loss: 0.6642 - acc: 0.9416 - val_loss: 0.5764 - val_acc: 0.9596\n",
      "Epoch 5/150\n",
      "891/891 [==============================] - 1s 562us/step - loss: 0.4106 - acc: 0.9697 - val_loss: 0.3981 - val_acc: 0.9697\n",
      "Epoch 6/150\n",
      "891/891 [==============================] - 0s 560us/step - loss: 0.2768 - acc: 0.9776 - val_loss: 0.3108 - val_acc: 0.9798\n",
      "Epoch 7/150\n",
      "891/891 [==============================] - 0s 556us/step - loss: 0.2014 - acc: 0.9955 - val_loss: 0.2373 - val_acc: 0.9899\n",
      "Epoch 8/150\n",
      "891/891 [==============================] - 0s 552us/step - loss: 0.1582 - acc: 0.9933 - val_loss: 0.1957 - val_acc: 1.0000\n",
      "Epoch 9/150\n",
      "891/891 [==============================] - 0s 561us/step - loss: 0.1266 - acc: 0.9978 - val_loss: 0.1746 - val_acc: 1.0000\n",
      "Epoch 10/150\n",
      "891/891 [==============================] - 1s 562us/step - loss: 0.1071 - acc: 0.9966 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 11/150\n",
      "891/891 [==============================] - 0s 552us/step - loss: 0.0911 - acc: 0.9978 - val_loss: 0.1494 - val_acc: 1.0000\n",
      "Epoch 12/150\n",
      "891/891 [==============================] - 0s 541us/step - loss: 0.0804 - acc: 0.9944 - val_loss: 0.1306 - val_acc: 1.0000\n",
      "Epoch 13/150\n",
      "891/891 [==============================] - 0s 556us/step - loss: 0.0711 - acc: 0.9966 - val_loss: 0.1190 - val_acc: 1.0000\n",
      "Epoch 14/150\n",
      "891/891 [==============================] - 0s 560us/step - loss: 0.0663 - acc: 0.9989 - val_loss: 0.1138 - val_acc: 1.0000\n",
      "Epoch 15/150\n",
      "891/891 [==============================] - 0s 557us/step - loss: 0.0595 - acc: 1.0000 - val_loss: 0.1104 - val_acc: 1.0000\n",
      "Epoch 16/150\n",
      "891/891 [==============================] - 0s 555us/step - loss: 0.0571 - acc: 1.0000 - val_loss: 0.0997 - val_acc: 1.0000\n",
      "Epoch 17/150\n",
      "891/891 [==============================] - 0s 556us/step - loss: 0.0512 - acc: 0.9989 - val_loss: 0.0937 - val_acc: 1.0000\n",
      "Epoch 18/150\n",
      "891/891 [==============================] - 0s 560us/step - loss: 0.0455 - acc: 1.0000 - val_loss: 0.0916 - val_acc: 1.0000\n",
      "Epoch 19/150\n",
      "891/891 [==============================] - 1s 568us/step - loss: 0.0435 - acc: 1.0000 - val_loss: 0.0889 - val_acc: 1.0000\n",
      "Epoch 20/150\n",
      "891/891 [==============================] - 0s 561us/step - loss: 0.0384 - acc: 0.9989 - val_loss: 0.0845 - val_acc: 1.0000\n",
      "Epoch 21/150\n",
      "891/891 [==============================] - 0s 556us/step - loss: 0.0374 - acc: 1.0000 - val_loss: 0.0791 - val_acc: 1.0000\n",
      "Epoch 22/150\n",
      "891/891 [==============================] - 1s 570us/step - loss: 0.0322 - acc: 1.0000 - val_loss: 0.0760 - val_acc: 1.0000\n",
      "Epoch 23/150\n",
      "891/891 [==============================] - 0s 556us/step - loss: 0.0335 - acc: 1.0000 - val_loss: 0.0735 - val_acc: 1.0000\n",
      "Epoch 24/150\n",
      "891/891 [==============================] - 1s 562us/step - loss: 0.0308 - acc: 1.0000 - val_loss: 0.0731 - val_acc: 1.0000\n",
      "Epoch 25/150\n",
      "891/891 [==============================] - 0s 555us/step - loss: 0.0293 - acc: 1.0000 - val_loss: 0.0728 - val_acc: 1.0000\n",
      "Epoch 26/150\n",
      "891/891 [==============================] - 0s 555us/step - loss: 0.0278 - acc: 1.0000 - val_loss: 0.0720 - val_acc: 1.0000\n",
      "Epoch 27/150\n",
      "891/891 [==============================] - 0s 555us/step - loss: 0.0253 - acc: 1.0000 - val_loss: 0.0689 - val_acc: 1.0000\n",
      "Epoch 28/150\n",
      "891/891 [==============================] - 0s 560us/step - loss: 0.0257 - acc: 1.0000 - val_loss: 0.0637 - val_acc: 1.0000\n",
      "Epoch 29/150\n",
      "891/891 [==============================] - 1s 564us/step - loss: 0.0238 - acc: 1.0000 - val_loss: 0.0615 - val_acc: 1.0000\n",
      "Epoch 30/150\n",
      "891/891 [==============================] - 1s 564us/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.0606 - val_acc: 1.0000\n",
      "Epoch 31/150\n",
      "891/891 [==============================] - 0s 550us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.0617 - val_acc: 1.0000\n",
      "Epoch 32/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0225 - acc: 1.0000 - val_loss: 0.0598 - val_acc: 1.0000\n",
      "Epoch 33/150\n",
      "891/891 [==============================] - 0s 553us/step - loss: 0.0213 - acc: 0.9989 - val_loss: 0.0571 - val_acc: 1.0000\n",
      "Epoch 34/150\n",
      "891/891 [==============================] - 0s 557us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.0542 - val_acc: 1.0000\n",
      "Epoch 35/150\n",
      "891/891 [==============================] - 0s 556us/step - loss: 0.0188 - acc: 1.0000 - val_loss: 0.0537 - val_acc: 1.0000\n",
      "Epoch 36/150\n",
      "891/891 [==============================] - 0s 560us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.0531 - val_acc: 1.0000\n",
      "Epoch 37/150\n",
      "891/891 [==============================] - 0s 557us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.0537 - val_acc: 1.0000\n",
      "Epoch 38/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.0520 - val_acc: 1.0000\n",
      "Epoch 39/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.0493 - val_acc: 1.0000\n",
      "Epoch 40/150\n",
      "891/891 [==============================] - 1s 587us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.0479 - val_acc: 1.0000\n",
      "Epoch 41/150\n",
      "891/891 [==============================] - 1s 568us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.0476 - val_acc: 1.0000\n",
      "Epoch 42/150\n",
      "891/891 [==============================] - 1s 565us/step - loss: 0.0155 - acc: 0.9989 - val_loss: 0.0464 - val_acc: 1.0000\n",
      "Epoch 43/150\n",
      "891/891 [==============================] - 1s 563us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0457 - val_acc: 1.0000\n",
      "Epoch 44/150\n",
      "891/891 [==============================] - 1s 562us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.0463 - val_acc: 1.0000\n",
      "Epoch 45/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.0449 - val_acc: 1.0000\n",
      "Epoch 46/150\n",
      "891/891 [==============================] - 1s 570us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.0445 - val_acc: 1.0000\n",
      "Epoch 47/150\n",
      "891/891 [==============================] - 1s 564us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0448 - val_acc: 1.0000\n",
      "Epoch 48/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 1.0000\n",
      "Epoch 49/150\n",
      "891/891 [==============================] - 0s 552us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0436 - val_acc: 1.0000\n",
      "Epoch 50/150\n",
      "891/891 [==============================] - 1s 567us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.0424 - val_acc: 1.0000\n",
      "Epoch 51/150\n",
      "891/891 [==============================] - 1s 570us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0418 - val_acc: 1.0000\n",
      "Epoch 52/150\n",
      "891/891 [==============================] - 1s 570us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 1.0000\n",
      "Epoch 53/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.0407 - val_acc: 1.0000\n",
      "Epoch 54/150\n",
      "891/891 [==============================] - 1s 594us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0400 - val_acc: 1.0000\n",
      "Epoch 55/150\n",
      "891/891 [==============================] - 1s 568us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0406 - val_acc: 1.0000\n",
      "Epoch 56/150\n",
      "891/891 [==============================] - 1s 582us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 1.0000\n",
      "Epoch 57/150\n",
      "891/891 [==============================] - 1s 575us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 1.0000\n",
      "Epoch 58/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0387 - val_acc: 1.0000\n",
      "Epoch 59/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0372 - val_acc: 1.0000\n",
      "Epoch 60/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0370 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150\n",
      "891/891 [==============================] - 1s 565us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 1.0000\n",
      "Epoch 62/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0371 - val_acc: 1.0000\n",
      "Epoch 63/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 1.0000\n",
      "Epoch 64/150\n",
      "891/891 [==============================] - 1s 566us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0354 - val_acc: 1.0000\n",
      "Epoch 65/150\n",
      "891/891 [==============================] - 0s 557us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0345 - val_acc: 1.0000\n",
      "Epoch 66/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 1.0000\n",
      "Epoch 67/150\n",
      "891/891 [==============================] - 1s 563us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0334 - val_acc: 1.0000\n",
      "Epoch 68/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0335 - val_acc: 1.0000\n",
      "Epoch 69/150\n",
      "891/891 [==============================] - 1s 565us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0332 - val_acc: 1.0000\n",
      "Epoch 70/150\n",
      "891/891 [==============================] - 1s 570us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0330 - val_acc: 1.0000\n",
      "Epoch 71/150\n",
      "891/891 [==============================] - 1s 565us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0334 - val_acc: 1.0000\n",
      "Epoch 72/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0334 - val_acc: 1.0000\n",
      "Epoch 73/150\n",
      "891/891 [==============================] - 0s 561us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0324 - val_acc: 1.0000\n",
      "Epoch 74/150\n",
      "891/891 [==============================] - 1s 563us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0309 - val_acc: 1.0000\n",
      "Epoch 75/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0301 - val_acc: 1.0000\n",
      "Epoch 76/150\n",
      "891/891 [==============================] - 1s 565us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0302 - val_acc: 1.0000\n",
      "Epoch 77/150\n",
      "891/891 [==============================] - 1s 574us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0306 - val_acc: 1.0000\n",
      "Epoch 78/150\n",
      "891/891 [==============================] - 1s 573us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0304 - val_acc: 1.0000\n",
      "Epoch 79/150\n",
      "891/891 [==============================] - 1s 580us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0304 - val_acc: 1.0000\n",
      "Epoch 80/150\n",
      "891/891 [==============================] - 1s 569us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0307 - val_acc: 1.0000\n",
      "Epoch 81/150\n",
      "891/891 [==============================] - 1s 572us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0305 - val_acc: 1.0000\n",
      "Epoch 82/150\n",
      "891/891 [==============================] - 1s 562us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0299 - val_acc: 1.0000\n",
      "Epoch 83/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0291 - val_acc: 1.0000\n",
      "Epoch 84/150\n",
      "891/891 [==============================] - 1s 570us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0287 - val_acc: 1.0000\n",
      "Epoch 85/150\n",
      "891/891 [==============================] - 1s 565us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0286 - val_acc: 1.0000\n",
      "Epoch 86/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 1.0000\n",
      "Epoch 87/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0278 - val_acc: 1.0000\n",
      "Epoch 88/150\n",
      "891/891 [==============================] - 1s 564us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0281 - val_acc: 1.0000\n",
      "Epoch 89/150\n",
      "891/891 [==============================] - 1s 581us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0281 - val_acc: 1.0000\n",
      "Epoch 90/150\n",
      "891/891 [==============================] - 1s 566us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 1.0000\n",
      "Epoch 91/150\n",
      "891/891 [==============================] - ETA: 0s - loss: 0.0047 - acc: 1.000 - 1s 588us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0281 - val_acc: 1.0000\n",
      "Epoch 92/150\n",
      "891/891 [==============================] - 1s 579us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 1.0000\n",
      "Epoch 93/150\n",
      "891/891 [==============================] - 1s 568us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0272 - val_acc: 1.0000\n",
      "Epoch 94/150\n",
      "891/891 [==============================] - 1s 583us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0261 - val_acc: 1.0000\n",
      "Epoch 95/150\n",
      "891/891 [==============================] - 1s 568us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0254 - val_acc: 1.0000\n",
      "Epoch 96/150\n",
      "891/891 [==============================] - 1s 562us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0253 - val_acc: 1.0000\n",
      "Epoch 97/150\n",
      "891/891 [==============================] - 0s 559us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0247 - val_acc: 1.0000\n",
      "Epoch 98/150\n",
      "891/891 [==============================] - 0s 560us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0247 - val_acc: 1.0000\n",
      "Epoch 99/150\n",
      "891/891 [==============================] - 1s 564us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0245 - val_acc: 1.0000\n",
      "Epoch 100/150\n",
      "891/891 [==============================] - 0s 554us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0242 - val_acc: 1.0000\n",
      "Epoch 101/150\n",
      "891/891 [==============================] - 0s 560us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 102/150\n",
      "891/891 [==============================] - 0s 557us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 103/150\n",
      "891/891 [==============================] - 1s 564us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "Epoch 104/150\n",
      "891/891 [==============================] - 0s 548us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0242 - val_acc: 1.0000\n",
      "Epoch 105/150\n",
      "891/891 [==============================] - 1s 570us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "Epoch 106/150\n",
      "891/891 [==============================] - 0s 544us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 1.0000\n",
      "Epoch 107/150\n",
      "891/891 [==============================] - 1s 571us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 1.0000\n",
      "Epoch 108/150\n",
      "891/891 [==============================] - 0s 546us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 1.0000\n",
      "Epoch 109/150\n",
      "891/891 [==============================] - 0s 552us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 1.0000\n",
      "Epoch 110/150\n",
      "891/891 [==============================] - 0s 552us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 1.0000\n",
      "Epoch 111/150\n",
      "891/891 [==============================] - 0s 559us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0239 - val_acc: 1.0000\n",
      "Epoch 112/150\n",
      "891/891 [==============================] - 0s 561us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 113/150\n",
      "891/891 [==============================] - 0s 550us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 1.0000\n",
      "Epoch 114/150\n",
      "891/891 [==============================] - 0s 554us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 1.0000\n",
      "Epoch 115/150\n",
      "891/891 [==============================] - 0s 557us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 1.0000\n",
      "Epoch 116/150\n",
      "891/891 [==============================] - 1s 563us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 1.0000\n",
      "Epoch 117/150\n",
      "891/891 [==============================] - 0s 556us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 1.0000\n",
      "Epoch 118/150\n",
      "891/891 [==============================] - 0s 555us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0224 - val_acc: 1.0000\n",
      "Epoch 119/150\n",
      "891/891 [==============================] - 0s 559us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0226 - val_acc: 1.0000\n",
      "Epoch 120/150\n",
      "891/891 [==============================] - 1s 566us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0223 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/150\n",
      "891/891 [==============================] - 0s 552us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 1.0000\n",
      "Epoch 122/150\n",
      "891/891 [==============================] - 0s 557us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 1.0000\n",
      "Epoch 123/150\n",
      "891/891 [==============================] - 0s 548us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 1.0000\n",
      "Epoch 124/150\n",
      "891/891 [==============================] - 0s 550us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 1.0000\n",
      "Epoch 125/150\n",
      "891/891 [==============================] - 0s 551us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 1.0000\n",
      "Epoch 126/150\n",
      "891/891 [==============================] - 0s 547us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0217 - val_acc: 1.0000\n",
      "Epoch 127/150\n",
      "891/891 [==============================] - 0s 551us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 1.0000\n",
      "Epoch 128/150\n",
      "891/891 [==============================] - 0s 557us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 1.0000\n",
      "Epoch 129/150\n",
      "891/891 [==============================] - 0s 551us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 1.0000\n",
      "Epoch 130/150\n",
      "891/891 [==============================] - 0s 554us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 131/150\n",
      "891/891 [==============================] - 0s 561us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0209 - val_acc: 1.0000\n",
      "Epoch 132/150\n",
      "891/891 [==============================] - 0s 551us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 1.0000\n",
      "Epoch 133/150\n",
      "891/891 [==============================] - 0s 547us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 1.0000\n",
      "Epoch 134/150\n",
      "891/891 [==============================] - 0s 548us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 135/150\n",
      "891/891 [==============================] - 0s 552us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 1.0000\n",
      "Epoch 136/150\n",
      "891/891 [==============================] - 0s 553us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0203 - val_acc: 1.0000\n",
      "Epoch 137/150\n",
      "891/891 [==============================] - 0s 546us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 1.0000\n",
      "Epoch 138/150\n",
      "891/891 [==============================] - 0s 557us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 1.0000\n",
      "Epoch 139/150\n",
      "891/891 [==============================] - 1s 565us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 1.0000\n",
      "Epoch 140/150\n",
      "891/891 [==============================] - 0s 541us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 1.0000\n",
      "Epoch 141/150\n",
      "891/891 [==============================] - 0s 547us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 1.0000\n",
      "Epoch 142/150\n",
      "891/891 [==============================] - 0s 559us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 143/150\n",
      "891/891 [==============================] - 0s 551us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 144/150\n",
      "891/891 [==============================] - 0s 554us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 145/150\n",
      "891/891 [==============================] - 0s 547us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 1.0000\n",
      "Epoch 146/150\n",
      "891/891 [==============================] - 0s 555us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 1.0000\n",
      "Epoch 147/150\n",
      "891/891 [==============================] - 0s 550us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 1.0000\n",
      "Epoch 148/150\n",
      "891/891 [==============================] - 0s 553us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 149/150\n",
      "891/891 [==============================] - 0s 556us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 150/150\n",
      "891/891 [==============================] - 0s 559us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1490289e588>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "#model5.fit(train_x_3, train_y_3, epochs = 100, verbose=1, validation_data=(validate_x_3, validate_y_3), callbacks=[history3])\n",
    "model5.fit(x, y, nb_epoch=150, batch_size=100, verbose=1, callbacks=[history5], validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Models\n",
    "\n",
    "Trained model information is saved for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1.save('models/model_1_0.29073.h5')\n",
    "#model2.save('models/model_2_0.29073.h5')\n",
    "#model3.save('models/model_3_0.29073.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same data pre-processing procedures on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_frame = pd.read_csv(LABEL_PATH + TEST_FILE_NAME)\n",
    "\n",
    "index = test_data_frame.pop('id')\n",
    "\n",
    "test_x = StandardScaler().fit(test_data_frame).transform(test_data_frame)\n",
    "#test_x = test_data_frame.get_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separately use the 3 models to predict the results based on the test X values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_1 = model1.predict_classes(test_x)\n",
    "test_y_2 = model2.predict_classes(test_x)\n",
    "test_y_3 = model3.predict_classes(test_x)\n",
    "test_y_4 = model4.predict_classes(test_x)\n",
    "test_y_5 = model5.predict_classes(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A summarised `test_y` object is generated and sorted by `loss` in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.0018897985302091616, 'name': 'test_y_1'},\n",
       " {'loss': 0.0019490449236210449, 'name': 'test_y_2'},\n",
       " {'loss': 0.001962117137916294, 'name': 'test_y_3'},\n",
       " {'loss': 0.0021756005603569225, 'name': 'test_y_4'},\n",
       " {'loss': 0.0020112577526841635, 'name': 'test_y_5'}]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = [\n",
    "    {\n",
    "        'name': 'test_y_1',\n",
    "        'predict': test_y_1,\n",
    "        'loss': history1.history['loss'][-1]\n",
    "    }, \n",
    "    {\n",
    "        'name': 'test_y_2',\n",
    "        'predict': test_y_2,\n",
    "        'loss': history2.history['loss'][-1]\n",
    "    }, \n",
    "    {\n",
    "        'name': 'test_y_3',\n",
    "        'predict': test_y_3,\n",
    "        'loss': history3.history['loss'][-1]\n",
    "    }, \n",
    "    {\n",
    "        'name': 'test_y_4',\n",
    "        'predict': test_y_4,\n",
    "        'loss': history4.history['loss'][-1]\n",
    "    }, \n",
    "    {\n",
    "        'name': 'test_y_5',\n",
    "        'predict': test_y_5,\n",
    "        'loss': history5.history['loss'][-1]\n",
    "    }, \n",
    "]\n",
    "\n",
    "test_y = sorted(test_y, key=lambda k: k['loss'])\n",
    "\n",
    "losses = [\n",
    "    {\n",
    "        'name': 'test_y_1',\n",
    "        'loss': history1.history['loss'][-1]\n",
    "    }, {\n",
    "        'name': 'test_y_2',\n",
    "        'loss': history2.history['loss'][-1]\n",
    "    }, {\n",
    "        'name': 'test_y_3',\n",
    "        'loss': history3.history['loss'][-1]\n",
    "    }, {\n",
    "        'name': 'test_y_4',\n",
    "        'loss': history4.history['loss'][-1]\n",
    "    }, {\n",
    "        'name': 'test_y_5',\n",
    "        'loss': history5.history['loss'][-1]\n",
    "    }, \n",
    "]\n",
    "\n",
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data_grid` is used to store the generated the file format which Kaggle competition will accept.\n",
    "\n",
    "Then iterate every predicted data and compare the results in the 3 models. \n",
    "\n",
    "If 2 or more models predict the same class, it will be the actual predicted class.\n",
    "\n",
    "If 3 models all predict different classes, then the value of the model with the least loss will be athe actual predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{51: 1}\n",
      "{50: 1}\n",
      "{1: 1}\n",
      "{19: 1}\n",
      "{14: 1}\n",
      "{3: 1}\n",
      "{3: 1}\n",
      "{28: 1}\n",
      "{84: 1}\n",
      "{8: 1}\n",
      "{43: 1}\n",
      "{74: 1}\n",
      "{75: 1}\n",
      "{10: 1}\n",
      "{52: 1}\n",
      "{46: 1}\n",
      "{45: 1}\n",
      "{73: 1}\n",
      "{13: 1}\n",
      "{71: 1}\n",
      "{61: 1}\n",
      "{68: 1}\n",
      "{57: 1}\n",
      "{77: 1}\n",
      "{1: 1}\n",
      "{70: 1}\n",
      "{28: 1}\n",
      "{15: 1}\n",
      "{35: 1}\n",
      "{70: 1}\n",
      "{53: 1}\n",
      "{74: 1}\n",
      "{47: 1}\n",
      "{50: 1}\n",
      "{4: 1}\n",
      "{36: 1}\n",
      "{14: 1}\n",
      "{55: 1}\n",
      "{36: 1}\n",
      "{93: 1}\n",
      "{8: 1}\n",
      "{32: 1}\n",
      "{8: 1}\n",
      "{9: 1}\n",
      "{71: 1}\n",
      "{70: 1}\n",
      "{38: 1}\n",
      "{23: 1}\n",
      "{94: 1}\n",
      "{18: 1}\n",
      "{17: 1}\n",
      "{5: 1}\n",
      "{55: 1}\n",
      "{94: 1}\n",
      "{14: 1}\n",
      "{86: 1}\n",
      "{62: 1}\n",
      "{33: 1}\n",
      "{51: 1}\n",
      "{98: 1}\n",
      "{88: 1}\n",
      "{56: 1}\n",
      "{21: 1}\n",
      "{59: 1}\n",
      "{65: 1}\n",
      "{11: 1}\n",
      "{48: 1}\n",
      "{5: 1}\n",
      "{13: 1}\n",
      "{4: 1}\n",
      "{54: 1}\n",
      "{57: 1}\n",
      "{29: 1}\n",
      "{7: 1}\n",
      "{31: 1}\n",
      "{98: 1}\n",
      "{92: 1}\n",
      "{84: 1}\n",
      "{25: 1}\n",
      "{10: 1}\n",
      "{61: 1}\n",
      "{43: 1}\n",
      "{85: 1}\n",
      "{24: 1}\n",
      "{1: 1}\n",
      "{2: 1}\n",
      "{23: 1}\n",
      "{83: 1}\n",
      "{40: 1}\n",
      "{22: 1}\n",
      "{48: 1}\n",
      "{90: 1}\n",
      "{25: 1}\n",
      "{21: 1}\n",
      "{37: 1}\n",
      "{56: 1}\n",
      "{41: 1}\n",
      "{95: 1}\n",
      "{7: 1}\n",
      "{89: 1}\n",
      "{98: 1}\n",
      "{77: 1}\n",
      "{3: 1}\n",
      "{12: 1}\n",
      "{31: 1}\n",
      "{84: 1}\n",
      "{53: 1}\n",
      "{96: 1}\n",
      "{64: 1}\n",
      "{72: 1}\n",
      "{93: 1}\n",
      "{93: 1}\n",
      "{67: 1}\n",
      "{30: 1}\n",
      "{8: 1}\n",
      "{88: 1}\n",
      "{60: 1}\n",
      "{87: 1}\n",
      "{6: 1}\n",
      "{57: 1}\n",
      "{34: 1}\n",
      "{90: 1}\n",
      "{60: 1}\n",
      "{17: 1}\n",
      "{75: 1}\n",
      "{27: 1}\n",
      "{51: 1}\n",
      "{31: 1}\n",
      "{39: 1}\n",
      "{23: 1}\n",
      "{24: 1}\n",
      "{2: 1}\n",
      "{41: 1}\n",
      "{61: 1}\n",
      "{24: 1}\n",
      "{97: 1}\n",
      "{29: 1}\n",
      "{28: 1}\n",
      "{68: 1}\n",
      "{81: 1}\n",
      "{42: 1}\n",
      "{51: 1}\n",
      "{86: 1}\n",
      "{62: 1}\n",
      "{60: 1}\n",
      "{52: 1}\n",
      "{95: 1}\n",
      "{64: 1}\n",
      "{42: 1}\n",
      "{96: 1}\n",
      "{95: 1}\n",
      "{20: 1}\n",
      "{59: 1}\n",
      "{35: 1}\n",
      "{86: 1}\n",
      "{1: 1}\n",
      "{26: 1}\n",
      "{38: 1}\n",
      "{43: 1}\n",
      "{75: 1}\n",
      "{20: 1}\n",
      "{60: 1}\n",
      "{46: 1}\n",
      "{79: 1}\n",
      "{22: 1}\n",
      "{79: 1}\n",
      "{69: 1}\n",
      "{87: 1}\n",
      "{65: 1}\n",
      "{97: 1}\n",
      "{75: 1}\n",
      "{21: 1}\n",
      "{29: 1}\n",
      "{21: 1}\n",
      "{11: 1}\n",
      "{10: 1}\n",
      "{58: 1}\n",
      "{94: 1}\n",
      "{27: 1}\n",
      "{22: 1}\n",
      "{15: 1}\n",
      "{45: 1}\n",
      "{89: 1}\n",
      "{54: 1}\n",
      "{43: 1}\n",
      "{5: 1}\n",
      "{23: 1}\n",
      "{94: 1}\n",
      "{40: 1}\n",
      "{49: 1}\n",
      "{89: 1}\n",
      "{72: 1}\n",
      "{36: 1}\n",
      "{11: 1}\n",
      "{81: 1}\n",
      "{95: 1}\n",
      "{18: 1}\n",
      "{91: 1}\n",
      "{29: 1}\n",
      "{64: 1}\n",
      "{80: 1}\n",
      "{6: 1}\n",
      "{78: 1}\n",
      "{45: 1}\n",
      "{28: 1}\n",
      "{9: 1}\n",
      "{78: 1}\n",
      "{90: 1}\n",
      "{44: 1}\n",
      "{89: 1}\n",
      "{92: 1}\n",
      "{13: 1}\n",
      "{2: 1}\n",
      "{59: 1}\n",
      "{0: 1}\n",
      "{96: 1}\n",
      "{70: 1}\n",
      "{32: 1}\n",
      "{29: 1}\n",
      "{78: 1}\n",
      "{91: 1}\n",
      "{55: 1}\n",
      "{44: 1}\n",
      "{38: 1}\n",
      "{5: 1}\n",
      "{60: 1}\n",
      "{49: 1}\n",
      "{58: 1}\n",
      "{94: 1}\n",
      "{67: 1}\n",
      "{92: 1}\n",
      "{88: 1}\n",
      "{90: 1}\n",
      "{79: 1}\n",
      "{25: 1}\n",
      "{37: 1}\n",
      "{18: 1}\n",
      "{0: 1}\n",
      "{76: 1}\n",
      "{27: 1}\n",
      "{70: 1}\n",
      "{71: 1}\n",
      "{44: 1}\n",
      "{70: 1}\n",
      "{32: 1}\n",
      "{90: 1}\n",
      "{30: 1}\n",
      "{82: 1}\n",
      "{34: 1}\n",
      "{30: 1}\n",
      "{82: 1}\n",
      "{96: 1}\n",
      "{48: 1}\n",
      "{65: 1}\n",
      "{57: 1}\n",
      "{64: 1}\n",
      "{26: 1}\n",
      "{53: 1}\n",
      "{55: 1}\n",
      "{73: 1}\n",
      "{9: 1}\n",
      "{3: 1}\n",
      "{83: 1}\n",
      "{26: 1}\n",
      "{30: 1}\n",
      "{63: 1}\n",
      "{17: 1}\n",
      "{22: 1}\n",
      "{79: 1}\n",
      "{63: 1}\n",
      "{12: 1}\n",
      "{78: 1}\n",
      "{36: 1}\n",
      "{14: 1}\n",
      "{27: 1}\n",
      "{25: 1}\n",
      "{67: 1}\n",
      "{38: 1}\n",
      "{20: 1}\n",
      "{54: 1}\n",
      "{76: 1}\n",
      "{69: 1}\n",
      "{67: 1}\n",
      "{97: 1}\n",
      "{80: 1}\n",
      "{44: 1}\n",
      "{92: 1}\n",
      "{69: 1}\n",
      "{23: 1}\n",
      "{21: 1}\n",
      "{16: 1}\n",
      "{51: 1}\n",
      "{33: 1}\n",
      "{77: 1}\n",
      "{16: 1}\n",
      "{11: 1}\n",
      "{97: 1}\n",
      "{1: 1}\n",
      "{52: 1}\n",
      "{39: 1}\n",
      "{24: 1}\n",
      "{52: 1}\n",
      "{42: 1}\n",
      "{17: 1}\n",
      "{2: 1}\n",
      "{73: 1}\n",
      "{96: 1}\n",
      "{83: 1}\n",
      "{88: 1}\n",
      "{9: 1}\n",
      "{63: 1}\n",
      "{50: 1}\n",
      "{16: 1}\n",
      "{38: 1}\n",
      "{87: 1}\n",
      "{95: 1}\n",
      "{3: 1}\n",
      "{35: 1}\n",
      "{83: 1}\n",
      "{60: 1}\n",
      "{59: 1}\n",
      "{58: 1}\n",
      "{0: 1}\n",
      "{50: 1}\n",
      "{62: 1}\n",
      "{38: 1}\n",
      "{93: 1}\n",
      "{68: 1}\n",
      "{55: 1}\n",
      "{46: 1}\n",
      "{19: 1}\n",
      "{46: 1}\n",
      "{94: 1}\n",
      "{18: 1}\n",
      "{0: 1}\n",
      "{33: 1}\n",
      "{89: 1}\n",
      "{40: 1}\n",
      "{62: 1}\n",
      "{48: 1}\n",
      "{42: 1}\n",
      "{6: 1}\n",
      "{31: 1}\n",
      "{91: 1}\n",
      "{73: 1}\n",
      "{81: 1}\n",
      "{12: 1}\n",
      "{85: 1}\n",
      "{47: 1}\n",
      "{6: 1}\n",
      "{79: 1}\n",
      "{2: 1}\n",
      "{22: 1}\n",
      "{35: 1}\n",
      "{43: 1}\n",
      "{6: 1}\n",
      "{80: 1}\n",
      "{78: 1}\n",
      "{82: 1}\n",
      "{5: 1}\n",
      "{61: 1}\n",
      "{37: 1}\n",
      "{43: 1}\n",
      "{33: 1}\n",
      "{69: 1}\n",
      "{56: 1}\n",
      "{71: 1}\n",
      "{45: 1}\n",
      "{59: 1}\n",
      "{42: 1}\n",
      "{66: 1}\n",
      "{86: 1}\n",
      "{98: 1}\n",
      "{83: 1}\n",
      "{90: 1}\n",
      "{64: 1}\n",
      "{82: 1}\n",
      "{11: 1}\n",
      "{79: 1}\n",
      "{56: 1}\n",
      "{76: 1}\n",
      "{49: 1}\n",
      "{48: 1}\n",
      "{20: 1}\n",
      "{74: 1}\n",
      "{15: 1}\n",
      "{33: 1}\n",
      "{49: 1}\n",
      "{89: 1}\n",
      "{44: 1}\n",
      "{7: 1}\n",
      "{35: 1}\n",
      "{13: 1}\n",
      "{55: 1}\n",
      "{23: 1}\n",
      "{34: 1}\n",
      "{44: 1}\n",
      "{32: 1}\n",
      "{30: 1}\n",
      "{36: 1}\n",
      "{9: 1}\n",
      "{72: 1}\n",
      "{31: 1}\n",
      "{61: 1}\n",
      "{50: 1}\n",
      "{82: 1}\n",
      "{34: 1}\n",
      "{29: 1}\n",
      "{22: 1}\n",
      "{92: 1}\n",
      "{72: 1}\n",
      "{11: 1}\n",
      "{19: 1}\n",
      "{4: 1}\n",
      "{87: 1}\n",
      "{51: 1}\n",
      "{80: 1}\n",
      "{39: 1}\n",
      "{84: 1}\n",
      "{32: 1}\n",
      "{66: 1}\n",
      "{36: 1}\n",
      "{41: 1}\n",
      "{31: 1}\n",
      "{80: 1}\n",
      "{4: 1}\n",
      "{26: 1}\n",
      "{68: 1}\n",
      "{96: 1}\n",
      "{20: 1}\n",
      "{40: 1}\n",
      "{34: 1}\n",
      "{39: 1}\n",
      "{56: 1}\n",
      "{73: 1}\n",
      "{76: 1}\n",
      "{84: 1}\n",
      "{7: 1}\n",
      "{67: 1}\n",
      "{37: 1}\n",
      "{8: 1}\n",
      "{95: 1}\n",
      "{85: 1}\n",
      "{62: 1}\n",
      "{10: 1}\n",
      "{65: 1}\n",
      "{41: 1}\n",
      "{2: 1}\n",
      "{17: 1}\n",
      "{86: 1}\n",
      "{41: 1}\n",
      "{52: 1}\n",
      "{3: 1}\n",
      "{49: 1}\n",
      "{47: 1}\n",
      "{76: 1}\n",
      "{52: 1}\n",
      "{16: 1}\n",
      "{26: 1}\n",
      "{88: 1}\n",
      "{63: 1}\n",
      "{45: 1}\n",
      "{39: 1}\n",
      "{66: 1}\n",
      "{87: 1}\n",
      "{75: 1}\n",
      "{74: 1}\n",
      "{7: 1}\n",
      "{64: 1}\n",
      "{65: 1}\n",
      "{78: 1}\n",
      "{63: 1}\n",
      "{56: 1}\n",
      "{21: 1}\n",
      "{61: 1}\n",
      "{88: 1}\n",
      "{62: 1}\n",
      "{91: 1}\n",
      "{59: 1}\n",
      "{12: 1}\n",
      "{74: 1}\n",
      "{15: 1}\n",
      "{85: 1}\n",
      "{8: 1}\n",
      "{66: 1}\n",
      "{57: 1}\n",
      "{83: 1}\n",
      "{82: 1}\n",
      "{72: 1}\n",
      "{58: 1}\n",
      "{28: 1}\n",
      "{17: 1}\n",
      "{67: 1}\n",
      "{66: 1}\n",
      "{57: 1}\n",
      "{66: 1}\n",
      "{75: 1}\n",
      "{35: 1}\n",
      "{18: 1}\n",
      "{9: 1}\n",
      "{54: 1}\n",
      "{91: 1}\n",
      "{65: 1}\n",
      "{19: 1}\n",
      "{15: 1}\n",
      "{10: 1}\n",
      "{24: 1}\n",
      "{71: 1}\n",
      "{69: 1}\n",
      "{48: 1}\n",
      "{39: 1}\n",
      "{98: 1}\n",
      "{16: 1}\n",
      "{19: 1}\n",
      "{45: 1}\n",
      "{74: 1}\n",
      "{6: 1}\n",
      "{67: 1}\n",
      "{42: 1}\n",
      "{34: 1}\n",
      "{80: 1}\n",
      "{47: 1}\n",
      "{85: 1}\n",
      "{28: 1}\n",
      "{85: 1}\n",
      "{47: 1}\n",
      "{25: 1}\n",
      "{27: 1}\n",
      "{58: 1}\n",
      "{68: 1}\n",
      "{84: 1}\n",
      "{97: 1}\n",
      "{63: 1}\n",
      "{97: 1}\n",
      "{76: 1}\n",
      "{81: 1}\n",
      "{87: 1}\n",
      "{77: 1}\n",
      "{13: 1}\n",
      "{0: 1}\n",
      "{28: 1}\n",
      "{41: 1}\n",
      "{14: 1}\n",
      "{12: 1}\n",
      "{33: 1}\n",
      "{86: 1}\n",
      "{46: 1}\n",
      "{4: 1}\n",
      "{4: 1}\n",
      "{47: 1}\n",
      "{30: 1}\n",
      "{19: 1}\n",
      "{58: 1}\n",
      "{13: 1}\n",
      "{77: 1}\n",
      "{98: 1}\n",
      "{5: 1}\n",
      "{49: 1}\n",
      "{72: 1}\n",
      "{53: 1}\n",
      "{32: 1}\n",
      "{77: 1}\n",
      "{40: 1}\n",
      "{68: 1}\n",
      "{26: 1}\n",
      "{92: 1}\n",
      "{16: 1}\n",
      "{81: 1}\n",
      "{37: 1}\n",
      "{14: 1}\n",
      "{93: 1}\n",
      "{80: 1}\n",
      "{53: 1}\n",
      "{46: 1}\n",
      "{25: 1}\n",
      "{50: 1}\n",
      "{7: 1}\n",
      "{37: 1}\n",
      "{93: 1}\n",
      "{0: 1}\n",
      "{20: 1}\n",
      "{54: 1}\n",
      "{10: 1}\n",
      "{91: 1}\n",
      "{40: 1}\n",
      "{81: 1}\n",
      "{53: 1}\n",
      "{18: 1}\n",
      "{27: 1}\n",
      "{1: 1}\n",
      "{12: 1}\n",
      "{54: 1}\n",
      "{73: 1}\n",
      "{15: 1}\n"
     ]
    }
   ],
   "source": [
    "data_grid = np.zeros((len(test_y_1), len(classes)))\n",
    "\n",
    "for i in range(len(test_y_1)):\n",
    "    count = {}\n",
    "    for test in test_y:\n",
    "        if test['predict'][i] not in count:\n",
    "            count[test['predict'][i]] = 1\n",
    "        else:\n",
    "            count[test['predict'][i]] += 1\n",
    "    \n",
    "    result = Counter(count)\n",
    "    predicted = result.most_common(1)\n",
    "    data_grid[i][predicted[0][0]] = 1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `pd.DataFrame` to generate CSV format variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(data_grid, index = index, columns = classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, write the variable into the CSV file for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission.csv','w') as file:\n",
    "    file.write(prediction.to_csv())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the same directory, run `kaggle competitions submit -c leaf-classification -f submission.csv -m \"Message\"` command to submit the CSV file to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
