{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaf Classfication \n",
    "A For CZ4041 Machine Learning Assignment from PT3 in AY2018/2019 Semester 2.\n",
    "The group members are:\n",
    "- LIU Yiqing\n",
    "- LUO Bingyi\n",
    "- TENG He Xu\n",
    "- WANG Jia\n",
    "- YI Zhiyue\n",
    "- ZHAO Ziru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries and Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "IMAGE_PATH = 'data/images/'\n",
    "LABEL_PATH = 'data/'\n",
    "TRAIN_FILE_NAME = 'train.csv'\n",
    "TEST_FILE_NAME = 'test.csv'\n",
    "COMMON_HEIGHT_WIDTH = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load images from the given path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path):\n",
    "    images = os.listdir(path)\n",
    "    loaded_images = []\n",
    "    \n",
    "    for i in range(num):\n",
    "        loaded_images.append(path + images[i])\n",
    "    return loaded_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize the images to a uniformed size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(file_name, hw):\n",
    "    image = cv2.imread(file_name, 0)\n",
    "    new_img = cv2.resize(image, (int(hw), int(hw)))\n",
    "    return np.reshape(new_img, (int(hw), int(hw), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load labels from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(file_path):\n",
    "    labels = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        csv_reader = csv.reader(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        # Skip the first line\n",
    "        next(csv_reader)\n",
    "        # Remove empty lines\n",
    "        lines = list(line for line in csv_reader if line)\n",
    "        for line in lines:\n",
    "            label = {}\n",
    "            label['id'] = int(line[0])\n",
    "            label['species'] = line[1]\n",
    "            labels.append(label)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images_and_labels(images, labels):\n",
    "    id = []\n",
    "    x = []\n",
    "    y = []\n",
    "    for image in images:\n",
    "        for label in labels:\n",
    "            if image['id'] == label['id']:\n",
    "                x.append(image['image'])\n",
    "                y.append(label['species'])\n",
    "                id.append( image['id'])\n",
    "    \n",
    "    return {\n",
    "        'id': np.array(id),\n",
    "        'x': np.array(x),\n",
    "        'y': np.array(y)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructDicitionary(labels):\n",
    "    uniqueLabels = list(set(list(map(lambda x: x[\"species\"], labels))))\n",
    "    dictionary = []\n",
    "    for i in range(len(uniqueLabels)):\n",
    "        dictionary.append({\n",
    "            \"number\": i,\n",
    "            \"text\": uniqueLabels[i]\n",
    "        })\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(dictionary, text):\n",
    "    for i in range(len(dictionary)):\n",
    "        if dictionary[i][\"text\"] == text:\n",
    "            return dictionary[i][\"number\"]\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(dictionary, number):\n",
    "    for i in range(len(dictionary)):\n",
    "        if dictionary[i][\"number\"] == number:\n",
    "            return dictionary[i][\"text\"]\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_images(IMAGE_PATH)\n",
    "train_labels = load_labels(LABEL_PATH + TRAIN_FILE_NAME)\n",
    "resized_images = []\n",
    "\n",
    "dictionary = constructDicitionary(train_labels)\n",
    "\n",
    "for i in range(len(images)):\n",
    "    resized_image = image_resize(images[i], COMMON_HEIGHT_WIDTH)\n",
    "    record = {}\n",
    "    record['id'] = int(images[i].split('.')[0].split('/')[2])\n",
    "    record['image'] = resized_image\n",
    "    resized_images.append(record)\n",
    "    \n",
    "## for img in resized_images:\n",
    "##     plt.imshow(img)\n",
    "##     plt.show()\n",
    "\n",
    "for j in range(len(train_labels)):\n",
    "    train_labels[j][\"species\"] = encode(dictionary, train_labels[j][\"species\"])\n",
    "\n",
    "train_data = combine_images_and_labels(resized_images, train_labels)\n",
    "train_x = train_data['x']\n",
    "train_y = train_data['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990,)\n",
      "[96 16 85 95 52 96  7 45 82 44 68 91 65 26 73  3 51  4 95 13 78 70 64 14  6\n",
      " 97 94 36  5 87 69  5 97 86 33  6 69 74 69 73 93 38 93 71 77 48  4 77  1 64\n",
      " 78 64 65 76 83 14 86 80 86 50 23 79 70 17 16 45 43 24 22 19 91 92 53 24 11\n",
      " 13 90 46 33 91 20 96 22 83 35  0 47 15 34  1 24 14 87 59 85 97 80 11 51 47\n",
      " 96 60 29 46 11 37 92 30  9 50 83 89 31 77 85 29 90 86 12  7  7 75 57 56 58\n",
      " 18 34 39 29 33 41 42 94 55 57 88 73 11  2 88 94 25 67 33 65 52 37 49 31 80\n",
      " 79  2 84 91 15 40 18 88 84 11 19 11 97 93 36 19 31 20 21 14 13 70  0 34 24\n",
      " 29 24 96  3 80 92 63 85 48 72 56 67  4 10  2 41  1 71 91 44 80 63 70 49 38\n",
      " 45 63 15 60 47 49 62 59 60 24 96 10 46 89 81 54 37 78 19 62  3 38 46 19 47\n",
      " 10 23 82 76  9 81 93 44 81 18  6 19  0 59 16 65 93 56 83 90 86  4 76 62 61\n",
      " 58 75 98 56 15 94 53 12 16 14 18  0 73 87 29 45  9 46 42  2 65 46 21 78 34\n",
      " 89 32 89  8 72 27 49 98 42 85 90 53 22 84 83 81 31 57 33 34 49 70 15 62 10\n",
      " 96 75 30 27 12  8  0 21 93 26 89 24 17 64 73 49 24 98 84 71 66 37 77 87  5\n",
      " 35 54 59 54 89 36 64 23 81 67 96 36 95 42 69 33 80 26 76 61 37 78 82 49 66\n",
      " 52 50 77 58  9 30 85 68 98 33 60  8 68 57 64 38 52 89 61 48 81 20 86 46 67\n",
      " 23 82 57 12  6 58 63 20 61 48 49 12 24 93 74  8  2 22 47 95 68 95 67 95  7\n",
      " 71 85 34 65 75 43 60 16 43 97 84 32 68 39 50  5 84  5 78 79 58 30 86 27 27\n",
      " 47 38 25 94 91 82 55  4 18 14 53 59 58 69 93 87 95 52 11 97 67 87 17 27 63\n",
      " 48 79 81 85 41 35  7 74  1 41 51  3 47 70 56 76 44 95  3 86 92  9 83 39 59\n",
      " 32 71 43 82 40 63 13 88 28 50 83 28 75 63 31 59 56 92 51 76  8 13 91 96 51\n",
      " 39 48 26 57 86 35 71 39 94 70 92 26 50 20 41 34 74 73 45 27 43 36 72 61 35\n",
      " 30 44 61 70 98 22 20 18 53  8 94 66  7  4 28  1  5 45 20 46 45 98 59 26 90\n",
      "  1 22 77 27 52 22 31 27 76 20 18 32 17 54 66 26 77 87 74  5 60 73 97 70 77\n",
      "  0 21 22  5 80  1 17 87 54 25 78 79 56 15 41 23 52 43 51 72 98 36 41 21 79\n",
      " 42  5 28 10 71 38 50 73 60 55  5 97 55 98 68 32 13 27 25 46 65 12 30 43 82\n",
      "  0 72 51 69 13 42 95 56 58 82 38 38 25 36 84  7 62 68 26 21 61 41 27 35  3\n",
      " 63 33 55 61 88 52 60 34 25 44  6 89 54 54 65 67 13 31 17 53  0 49 90 28 40\n",
      " 52 74 98 72 85 18 58 66  0 53 18 68 17 92 17 35 75 26 80 22 47 16 35 97 39\n",
      " 53 81 32 65 68 75  3 85 58  9 73 87 44 87 64 73 53 41 83 84  1  4 61 14 36\n",
      " 32 55 15 97 39 66 42 60 20 84 38 66 66 37 28 79 83 76 49 21  2 19 67 33 30\n",
      " 88 43  3 71 29 55 40 23 33 37 92 77 40 14 39 12 52 57 93 11  6 64 92  4  9\n",
      "  6 31 32 66 29 31 20 34 50 40  4 25 12 79 11 62 90 12 36 44 21 45 28 29 42\n",
      " 21 43 74 74 62 40 12 26  1 15  9 43 47 16 75 78  7 90 69 72  1 80 40 76 41\n",
      " 57 44  6 72  7 51 37 88 45 93  0 15 25 24 75 29 74 89 21 83 70 44  2 60 82\n",
      " 63 94 10  8 35 56 48 69 92 37 71 48 23 72 69 16 18 61 48 53 55 88 84 51 14\n",
      " 68 40 64 16 62 25 57 19 30 66 94 15 94 23 89 79 62 79 69  7 10 39 29 13 88\n",
      " 14 23 37 11 74 54 46  2 25 19 17  9 40 32 63  3 82  2 10 42 67 91 91 98 67\n",
      " 76 96  6 35 81 54 50 17  8 50 59 19 51 48 91 71 10 80  6 88 36  9 28 59 23\n",
      " 78 72 55 38 30 16  8 65  3 13 47  8 62 77 86 39 95 81 78  4 90 28 45 55 54\n",
      " 64 22 56 31  2 32 10 30 58 90 34 28 57 75 42]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_y))\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 22, 22, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 9, 9, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 99)                6435      \n",
      "=================================================================\n",
      "Total params: 100,099\n",
      "Trainable params: 100,099\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lane0\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(50, 50, 1...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\lane0\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  import sys\n",
      "c:\\users\\lane0\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(50, 50, 1)))       \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(99, activation=tf.nn.softmax))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 50, 50, 1)\n",
      "(990,)\n",
      "Epoch 1/30\n",
      "990/990 [==============================] - 3s 3ms/step - loss: 3.3529 - acc: 0.1667\n",
      "Epoch 2/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 3.1069 - acc: 0.1899\n",
      "Epoch 3/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 3.0552 - acc: 0.2071\n",
      "Epoch 4/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 2.8450 - acc: 0.2414\n",
      "Epoch 5/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 2.7908 - acc: 0.2545\n",
      "Epoch 6/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 2.7730 - acc: 0.2434\n",
      "Epoch 7/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 2.6266 - acc: 0.2879\n",
      "Epoch 8/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 2.4921 - acc: 0.3071\n",
      "Epoch 9/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 2.4403 - acc: 0.3081\n",
      "Epoch 10/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 2.3086 - acc: 0.3253\n",
      "Epoch 11/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 2.3005 - acc: 0.3566\n",
      "Epoch 12/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 2.3149 - acc: 0.3313\n",
      "Epoch 13/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 2.1433 - acc: 0.3677\n",
      "Epoch 14/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 2.0607 - acc: 0.3939\n",
      "Epoch 15/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 2.0526 - acc: 0.4020\n",
      "Epoch 16/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 1.9975 - acc: 0.4091\n",
      "Epoch 17/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 1.9228 - acc: 0.4192\n",
      "Epoch 18/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 1.9501 - acc: 0.4121\n",
      "Epoch 19/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 1.9112 - acc: 0.4081\n",
      "Epoch 20/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 1.8152 - acc: 0.4616\n",
      "Epoch 21/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 1.7938 - acc: 0.4444\n",
      "Epoch 22/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 1.8117 - acc: 0.4394A: 0s - loss: 1.7786 -\n",
      "Epoch 23/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 1.7511 - acc: 0.4596\n",
      "Epoch 24/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 1.7232 - acc: 0.4697\n",
      "Epoch 25/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 1.7161 - acc: 0.4737\n",
      "Epoch 26/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 1.7137 - acc: 0.4788\n",
      "Epoch 27/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 1.6743 - acc: 0.4818\n",
      "Epoch 28/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 1.6035 - acc: 0.4949A: 0s - loss: 1.5856 - acc:\n",
      "Epoch 29/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 1.5995 - acc: 0.5121\n",
      "Epoch 30/30\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 1.5676 - acc: 0.5040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2025470ac50>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "print(np.shape(train_x))\n",
    "print(np.shape(train_y))\n",
    "model.fit(train_x, train_y, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = load_labels(LABEL_PATH + TEST_FILE_NAME)\n",
    "\n",
    "for k in range(len(test_labels)):\n",
    "    test_labels[k][\"species\"] = encode(dictionary, test_labels[k][\"species\"])\n",
    "\n",
    "test_data = combine_images_and_labels(resized_images, test_labels)\n",
    "\n",
    "test_x = test_data['x']\n",
    "test_y = test_data['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(test_x)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "with open('submission.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['id']\n",
    "    \n",
    "    label_fieldslist = list(set(list(map(lambda x: x[\"species\"], train_labels))))\n",
    "    for i in range(len(label_fieldslist)):\n",
    "        fieldnames.append(decode(dictionary, label_fieldslist[i]))\n",
    "        \n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for n in range(len(output)):\n",
    "        #print(np.argmax(output[n]))\n",
    "        row = {}\n",
    "        for field in fieldnames:\n",
    "            species = decode(dictionary, np.argmax(output[n]))\n",
    "            row[\"id\"] = test_data['id'][n]\n",
    "            row[species] = 1\n",
    "            if field not in [\"id\", species]:\n",
    "                row[field] = 0\n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
