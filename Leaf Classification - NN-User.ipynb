{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaf Classfication \n",
    "A For CZ4041 Machine Learning Assignment from PT3 in AY2018/2019 Semester 2.\n",
    "The group members are:\n",
    "- LIU Yiqing\n",
    "- LUO Bingyi\n",
    "- TENG He Xu\n",
    "- WANG Jia\n",
    "- YI Zhiyue\n",
    "- ZHAO Ziru\n",
    "\n",
    "The Kaggle problem is here https://www.kaggle.com/c/leaf-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries and Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import History \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histories are to record model losses in every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = History()\n",
    "history2 = History()\n",
    "history3 = History()\n",
    "history4 = History()\n",
    "history5 = History()\n",
    "\n",
    "LABEL_PATH = 'data/'\n",
    "TRAIN_FILE_NAME = 'train.csv'\n",
    "TEST_FILE_NAME = 'test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load From CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load features and labels from the train csv file\n",
    "\n",
    "y is extracted from the `species` column and converted from text string to numeric values as classes\n",
    "\n",
    "x contains features in the remaining columns except `id` columns. `StandardScaler` is used to transform the data so that its distribution will have a `mean = 0` and standard `deviation = 1`. It is to standardize the scale of the data for ease of computation and remain the features unaffected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_frame = pd.read_csv(LABEL_PATH + TRAIN_FILE_NAME)\n",
    "\n",
    "train_data_frame = train_data_frame.drop(['id'], axis=1)\n",
    "\n",
    "y = train_data_frame.pop('species')\n",
    "classes = np.unique(y)\n",
    "\n",
    "y = to_categorical(LabelEncoder().fit(y).transform(y))\n",
    "\n",
    "x = StandardScaler().fit(train_data_frame).transform(train_data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `StratifiedShuffleSplit` to randomly split the data set into training data and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_1 dimention:  (792, 99)\n",
      "validate_x_1 dimention:    (198, 192)\n",
      "train_x_2 dimention:  (792, 99)\n",
      "validate_x_2 dimention:    (198, 192)\n",
      "train_x_3 dimention:  (792, 99)\n",
      "validate_x_3 dimention:    (198, 192)\n"
     ]
    }
   ],
   "source": [
    "sss_1 = StratifiedShuffleSplit(n_splits=10, test_size=0.2)\n",
    "sss_2 = StratifiedShuffleSplit(n_splits=20, test_size=0.2)\n",
    "sss_3 = StratifiedShuffleSplit(n_splits=30, test_size=0.2)\n",
    "\n",
    "train_index_1, validation_index_1 = next(iter(sss_1.split(x, y)))\n",
    "train_x_1, validate_x_1 = x[train_index_1], x[validation_index_1]\n",
    "train_y_1, validate_y_1 = y[train_index_1], y[validation_index_1]\n",
    "\n",
    "train_index_2, validation_index_2 = next(iter(sss_2.split(x, y)))\n",
    "train_x_2, validate_x_2 = x[train_index_2], x[validation_index_2]\n",
    "train_y_2, validate_y_2 = y[train_index_2], y[validation_index_2]\n",
    "\n",
    "train_index_3, validation_index_3 = next(iter(sss_3.split(x, y)))\n",
    "train_x_3, validate_x_3 = x[train_index_3], x[validation_index_3]\n",
    "train_y_3, validate_y_3 = y[train_index_3], y[validation_index_3]\n",
    "\n",
    "print(\"train_x_1 dimention: \",train_y_1.shape)\n",
    "print(\"validate_x_1 dimention:   \",validate_x_1.shape)\n",
    "\n",
    "print(\"train_x_2 dimention: \",train_y_2.shape)\n",
    "print(\"validate_x_2 dimention:   \",validate_x_2.shape)\n",
    "\n",
    "print(\"train_x_3 dimention: \",train_y_3.shape)\n",
    "print(\"validate_x_3 dimention:   \",validate_x_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of classes for later computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_classes = len(np.unique(train_y, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "\n",
    "Use ensemble learning method to predict the value.\n",
    "\n",
    "Ensemble learning refers to training multiple models with the same set of training data set and validation data set. With multiple sets of models, a pool of predicted values can be generated. We can pick the most possible predicted value from the pool to achieve the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Dense(768, kernel_initializer='glorot_normal', activation='tanh', input_dim = train_x.shape[1]))\n",
    "model1.add(Dropout(0.4))\n",
    "model1.add(Dense(768, activation='tanh'))\n",
    "model1.add(Dropout(0.4))\n",
    "model1.add(Dense(no_of_classes, activation=tf.nn.softmax))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(1000, activation='relu', input_dim = train_x.shape[1]))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(1000, activation='relu'))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(no_of_classes, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Dense(500, activation='relu', input_dim = train_x.shape[1]))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(500, activation='relu'))\n",
    "model3.add(Dropout(0.4))\n",
    "model3.add(Dense(no_of_classes, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and fit the model\n",
    "\n",
    "At this stage, the data is pumped into the model and Keras will help to run iterations to reduce the loss as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 792 samples, validate on 198 samples\n",
      "Epoch 1/50\n",
      "792/792 [==============================] - 9s 11ms/step - loss: 2.4498 - acc: 0.4848 - val_loss: 0.5380 - val_acc: 0.9394\n",
      "Epoch 2/50\n",
      "792/792 [==============================] - 0s 576us/step - loss: 0.5733 - acc: 0.9205 - val_loss: 0.1836 - val_acc: 0.9899\n",
      "Epoch 3/50\n",
      "792/792 [==============================] - 0s 575us/step - loss: 0.2350 - acc: 0.9773 - val_loss: 0.0951 - val_acc: 0.9798\n",
      "Epoch 4/50\n",
      "792/792 [==============================] - 1s 631us/step - loss: 0.1389 - acc: 0.9773 - val_loss: 0.0800 - val_acc: 0.9798\n",
      "Epoch 5/50\n",
      "792/792 [==============================] - 0s 607us/step - loss: 0.0736 - acc: 0.9899 - val_loss: 0.0553 - val_acc: 0.9899\n",
      "Epoch 6/50\n",
      "792/792 [==============================] - 0s 585us/step - loss: 0.0456 - acc: 0.9962 - val_loss: 0.0175 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "792/792 [==============================] - 0s 623us/step - loss: 0.0502 - acc: 0.9912 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "792/792 [==============================] - 0s 577us/step - loss: 0.0165 - acc: 0.9987 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "792/792 [==============================] - 0s 566us/step - loss: 0.0160 - acc: 0.9987 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "792/792 [==============================] - 0s 572us/step - loss: 0.0148 - acc: 0.9962 - val_loss: 0.0113 - val_acc: 0.9949\n",
      "Epoch 11/50\n",
      "792/792 [==============================] - 0s 586us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "792/792 [==============================] - 0s 591us/step - loss: 0.0130 - acc: 0.9975 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "792/792 [==============================] - 1s 831us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "792/792 [==============================] - 1s 770us/step - loss: 0.0071 - acc: 0.9987 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "792/792 [==============================] - 1s 861us/step - loss: 0.0117 - acc: 0.9962 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "792/792 [==============================] - 0s 623us/step - loss: 7.9012e-04 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9949\n",
      "Epoch 17/50\n",
      "792/792 [==============================] - 0s 625us/step - loss: 6.5870e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "792/792 [==============================] - 0s 623us/step - loss: 5.4200e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "792/792 [==============================] - 0s 629us/step - loss: 0.0099 - acc: 0.9949 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "792/792 [==============================] - 1s 668us/step - loss: 2.9285e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "792/792 [==============================] - 1s 684us/step - loss: 2.5285e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "792/792 [==============================] - 0s 510us/step - loss: 0.0016 - acc: 0.9987 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "792/792 [==============================] - 0s 549us/step - loss: 1.2820e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "792/792 [==============================] - 0s 615us/step - loss: 1.6955e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "792/792 [==============================] - 0s 514us/step - loss: 0.0028 - acc: 0.9987 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "792/792 [==============================] - 1s 775us/step - loss: 6.7684e-05 - acc: 1.0000 - val_loss: 6.6459e-04 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "792/792 [==============================] - 1s 826us/step - loss: 1.0520e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "792/792 [==============================] - 1s 678us/step - loss: 0.0023 - acc: 0.9987 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "792/792 [==============================] - 0s 543us/step - loss: 9.3951e-05 - acc: 1.0000 - val_loss: 7.7404e-04 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "792/792 [==============================] - 0s 558us/step - loss: 3.7090e-05 - acc: 1.0000 - val_loss: 5.3356e-04 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "792/792 [==============================] - 0s 548us/step - loss: 1.1390e-04 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 0.9949\n",
      "Epoch 32/50\n",
      "792/792 [==============================] - 1s 738us/step - loss: 0.0076 - acc: 0.9987 - val_loss: 7.2579e-04 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "792/792 [==============================] - 0s 612us/step - loss: 9.3970e-05 - acc: 1.0000 - val_loss: 6.8350e-04 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "792/792 [==============================] - 0s 505us/step - loss: 2.3112e-05 - acc: 1.0000 - val_loss: 5.8789e-04 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "792/792 [==============================] - 0s 516us/step - loss: 5.6698e-04 - acc: 1.0000 - val_loss: 2.4450e-04 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "792/792 [==============================] - 1s 692us/step - loss: 1.6163e-05 - acc: 1.0000 - val_loss: 5.4254e-04 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "792/792 [==============================] - 1s 692us/step - loss: 2.0209e-05 - acc: 1.0000 - val_loss: 4.5569e-04 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "792/792 [==============================] - 0s 565us/step - loss: 0.0088 - acc: 0.9987 - val_loss: 7.1402e-04 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "792/792 [==============================] - 0s 523us/step - loss: 3.5128e-05 - acc: 1.0000 - val_loss: 6.3495e-04 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "792/792 [==============================] - 1s 677us/step - loss: 1.9980e-04 - acc: 1.0000 - val_loss: 6.8972e-04 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "792/792 [==============================] - 1s 763us/step - loss: 8.2053e-06 - acc: 1.0000 - val_loss: 7.0953e-04 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "792/792 [==============================] - 0s 626us/step - loss: 1.6119e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "792/792 [==============================] - 0s 579us/step - loss: 6.1660e-06 - acc: 1.0000 - val_loss: 6.4594e-04 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "792/792 [==============================] - 0s 582us/step - loss: 3.8403e-06 - acc: 1.0000 - val_loss: 6.1117e-04 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "792/792 [==============================] - 0s 564us/step - loss: 6.2435e-06 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9949\n",
      "Epoch 46/50\n",
      "792/792 [==============================] - 0s 512us/step - loss: 0.0029 - acc: 0.9987 - val_loss: 3.7326e-04 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "792/792 [==============================] - 0s 508us/step - loss: 9.1291e-06 - acc: 1.0000 - val_loss: 4.5948e-04 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "792/792 [==============================] - 0s 598us/step - loss: 2.5171e-06 - acc: 1.0000 - val_loss: 4.9409e-04 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "792/792 [==============================] - 1s 721us/step - loss: 8.6384e-06 - acc: 1.0000 - val_loss: 6.2495e-04 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "792/792 [==============================] - 1s 711us/step - loss: 2.1264e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18ca73898>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(loss='categorical_crossentropy',optimizer='rmsprop', metrics = [\"accuracy\"])\n",
    "model1.fit(train_x, train_y, epochs = 50, verbose=1, validation_data=(validate_x_1, validate_y_1), callbacks=[history1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 792 samples, validate on 198 samples\n",
      "Epoch 1/50\n",
      "792/792 [==============================] - 10s 13ms/step - loss: 2.8695 - acc: 0.4066 - val_loss: 0.6512 - val_acc: 0.8889\n",
      "Epoch 2/50\n",
      "792/792 [==============================] - 1s 989us/step - loss: 0.5460 - acc: 0.8775 - val_loss: 0.2489 - val_acc: 0.9141\n",
      "Epoch 3/50\n",
      "792/792 [==============================] - 1s 979us/step - loss: 0.2252 - acc: 0.9482 - val_loss: 0.0965 - val_acc: 0.9798\n",
      "Epoch 4/50\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.1236 - acc: 0.9672 - val_loss: 0.1178 - val_acc: 0.9747\n",
      "Epoch 5/50\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0805 - acc: 0.9785 - val_loss: 0.1133 - val_acc: 0.9747\n",
      "Epoch 6/50\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.0775 - acc: 0.9811 - val_loss: 0.0993 - val_acc: 0.9646\n",
      "Epoch 7/50\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0744 - acc: 0.9785 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.1003 - acc: 0.9785 - val_loss: 0.0774 - val_acc: 0.9798\n",
      "Epoch 9/50\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.9987 - val_loss: 0.0262 - val_acc: 0.9949\n",
      "Epoch 10/50\n",
      "792/792 [==============================] - 1s 990us/step - loss: 0.0458 - acc: 0.9848 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0183 - acc: 0.9962 - val_loss: 0.0210 - val_acc: 0.9949\n",
      "Epoch 12/50\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0170 - acc: 0.9962 - val_loss: 0.0683 - val_acc: 0.9798\n",
      "Epoch 13/50\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.0467 - acc: 0.9874 - val_loss: 0.0303 - val_acc: 0.9848\n",
      "Epoch 14/50\n",
      "792/792 [==============================] - 1s 903us/step - loss: 0.0125 - acc: 0.9975 - val_loss: 0.0515 - val_acc: 0.9899\n",
      "Epoch 15/50\n",
      "792/792 [==============================] - 1s 924us/step - loss: 0.0168 - acc: 0.9949 - val_loss: 0.0248 - val_acc: 0.9899\n",
      "Epoch 16/50\n",
      "792/792 [==============================] - 1s 913us/step - loss: 0.0216 - acc: 0.9949 - val_loss: 0.0225 - val_acc: 0.9949\n",
      "Epoch 17/50\n",
      "792/792 [==============================] - 1s 869us/step - loss: 0.0161 - acc: 0.9949 - val_loss: 0.0989 - val_acc: 0.9848\n",
      "Epoch 18/50\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0082 - acc: 0.9987 - val_loss: 0.0260 - val_acc: 0.9899\n",
      "Epoch 19/50\n",
      "792/792 [==============================] - 1s 846us/step - loss: 0.0026 - acc: 0.9987 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "792/792 [==============================] - 1s 808us/step - loss: 0.0066 - acc: 0.9987 - val_loss: 0.0218 - val_acc: 0.9848\n",
      "Epoch 21/50\n",
      "792/792 [==============================] - 1s 806us/step - loss: 0.0157 - acc: 0.9962 - val_loss: 0.0482 - val_acc: 0.9848\n",
      "Epoch 22/50\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0069 - acc: 0.9975 - val_loss: 0.0185 - val_acc: 0.9949\n",
      "Epoch 23/50\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0311 - acc: 0.9886 - val_loss: 0.0070 - val_acc: 0.9949\n",
      "Epoch 24/50\n",
      "792/792 [==============================] - 1s 969us/step - loss: 1.8381e-04 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "792/792 [==============================] - 1s 884us/step - loss: 0.0026 - acc: 0.9987 - val_loss: 0.1272 - val_acc: 0.9798\n",
      "Epoch 26/50\n",
      "792/792 [==============================] - 1s 905us/step - loss: 0.0491 - acc: 0.9937 - val_loss: 0.0168 - val_acc: 0.9899\n",
      "Epoch 27/50\n",
      "792/792 [==============================] - 1s 950us/step - loss: 4.7806e-04 - acc: 1.0000 - val_loss: 0.0305 - val_acc: 0.9899\n",
      "Epoch 28/50\n",
      "792/792 [==============================] - 1s 903us/step - loss: 5.5171e-04 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 0.9899\n",
      "Epoch 29/50\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.0087 - acc: 0.9975 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "792/792 [==============================] - 1s 886us/step - loss: 1.1433e-04 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9899\n",
      "Epoch 31/50\n",
      "792/792 [==============================] - 1s 855us/step - loss: 0.0036 - acc: 0.9987 - val_loss: 0.0082 - val_acc: 0.9949\n",
      "Epoch 32/50\n",
      "792/792 [==============================] - 1s 833us/step - loss: 7.2492e-04 - acc: 1.0000 - val_loss: 0.1895 - val_acc: 0.9798\n",
      "Epoch 33/50\n",
      "792/792 [==============================] - 1s 848us/step - loss: 0.0642 - acc: 0.9949 - val_loss: 4.8615e-04 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "792/792 [==============================] - 1s 860us/step - loss: 2.5964e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "792/792 [==============================] - 1s 819us/step - loss: 3.0159e-04 - acc: 1.0000 - val_loss: 0.0631 - val_acc: 0.9949\n",
      "Epoch 36/50\n",
      "792/792 [==============================] - 1s 828us/step - loss: 0.0037 - acc: 0.9987 - val_loss: 2.5783e-04 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "792/792 [==============================] - 1s 810us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 0.9949\n",
      "Epoch 38/50\n",
      "792/792 [==============================] - 1s 789us/step - loss: 0.0116 - acc: 0.9987 - val_loss: 0.0090 - val_acc: 0.9949\n",
      "Epoch 39/50\n",
      "792/792 [==============================] - 1s 788us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "792/792 [==============================] - 1s 800us/step - loss: 5.1784e-04 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9949\n",
      "Epoch 41/50\n",
      "792/792 [==============================] - 1s 759us/step - loss: 4.6293e-05 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "792/792 [==============================] - 1s 761us/step - loss: 0.0104 - acc: 0.9937 - val_loss: 0.0300 - val_acc: 0.9899\n",
      "Epoch 43/50\n",
      "792/792 [==============================] - 1s 770us/step - loss: 1.7575e-04 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 0.9949\n",
      "Epoch 44/50\n",
      "792/792 [==============================] - 1s 780us/step - loss: 0.0200 - acc: 0.9987 - val_loss: 1.0535e-04 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "792/792 [==============================] - 1s 767us/step - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "792/792 [==============================] - 1s 766us/step - loss: 2.4802e-04 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 0.9949\n",
      "Epoch 47/50\n",
      "792/792 [==============================] - 1s 765us/step - loss: 0.0249 - acc: 0.9975 - val_loss: 8.2867e-04 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "792/792 [==============================] - 1s 771us/step - loss: 0.0206 - acc: 0.9987 - val_loss: 0.0679 - val_acc: 0.9899\n",
      "Epoch 49/50\n",
      "792/792 [==============================] - 1s 771us/step - loss: 0.0058 - acc: 0.9975 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "792/792 [==============================] - 1s 765us/step - loss: 4.4630e-04 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 0.9949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18ce9a3c8>"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model2.fit(train_x, train_y, epochs = 50, verbose=1, validation_data=(validate_x_2, validate_y_2), callbacks=[history2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 792 samples, validate on 198 samples\n",
      "Epoch 1/50\n",
      "792/792 [==============================] - 8s 10ms/step - loss: 0.0098 - acc: 0.9962 - val_loss: 7.8468e-04 - val_acc: 1.0000\n",
      "Epoch 2/50\n",
      "792/792 [==============================] - 0s 415us/step - loss: 0.0122 - acc: 0.9975 - val_loss: 0.0548 - val_acc: 0.9848\n",
      "Epoch 3/50\n",
      "792/792 [==============================] - 0s 421us/step - loss: 0.0162 - acc: 0.9937 - val_loss: 7.9362e-05 - val_acc: 1.0000\n",
      "Epoch 4/50\n",
      "792/792 [==============================] - 0s 399us/step - loss: 0.0037 - acc: 0.9987 - val_loss: 2.0688e-04 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "792/792 [==============================] - 0s 417us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.7002e-04 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "792/792 [==============================] - 0s 418us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "792/792 [==============================] - 0s 377us/step - loss: 0.0105 - acc: 0.9975 - val_loss: 2.4820e-04 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "792/792 [==============================] - 0s 421us/step - loss: 0.0069 - acc: 0.9975 - val_loss: 1.1817e-04 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "792/792 [==============================] - 0s 384us/step - loss: 4.1757e-04 - acc: 1.0000 - val_loss: 2.6419e-04 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "792/792 [==============================] - 0s 426us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 8.7664e-04 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "792/792 [==============================] - 0s 427us/step - loss: 0.0140 - acc: 0.9949 - val_loss: 1.0494e-04 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "792/792 [==============================] - 0s 423us/step - loss: 1.9394e-04 - acc: 1.0000 - val_loss: 6.4237e-05 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "792/792 [==============================] - 0s 429us/step - loss: 0.0057 - acc: 0.9975 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "792/792 [==============================] - 0s 452us/step - loss: 0.0081 - acc: 0.9987 - val_loss: 1.8458e-04 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "792/792 [==============================] - 0s 431us/step - loss: 0.0180 - acc: 0.9949 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "792/792 [==============================] - 0s 420us/step - loss: 0.0024 - acc: 0.9987 - val_loss: 1.0713e-04 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "792/792 [==============================] - 0s 425us/step - loss: 4.3801e-04 - acc: 1.0000 - val_loss: 4.0016e-04 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "792/792 [==============================] - 0s 430us/step - loss: 0.0035 - acc: 0.9975 - val_loss: 2.7384e-04 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "792/792 [==============================] - 0s 411us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 0.9949\n",
      "Epoch 20/50\n",
      "792/792 [==============================] - 0s 519us/step - loss: 2.3093e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "792/792 [==============================] - 0s 573us/step - loss: 0.0022 - acc: 0.9987 - val_loss: 6.8685e-04 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "792/792 [==============================] - 0s 579us/step - loss: 0.0025 - acc: 0.9987 - val_loss: 4.8894e-05 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "792/792 [==============================] - 0s 539us/step - loss: 0.0155 - acc: 0.9987 - val_loss: 3.1436e-04 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "792/792 [==============================] - 0s 522us/step - loss: 8.0552e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "792/792 [==============================] - 0s 431us/step - loss: 1.9311e-04 - acc: 1.0000 - val_loss: 2.2579e-04 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "792/792 [==============================] - 0s 441us/step - loss: 0.0031 - acc: 0.9987 - val_loss: 6.9008e-04 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "792/792 [==============================] - 0s 538us/step - loss: 9.2587e-04 - acc: 1.0000 - val_loss: 1.4192e-04 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "792/792 [==============================] - 0s 429us/step - loss: 6.2534e-04 - acc: 1.0000 - val_loss: 1.2686e-04 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "792/792 [==============================] - 0s 476us/step - loss: 3.1132e-04 - acc: 1.0000 - val_loss: 9.2369e-04 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "792/792 [==============================] - 0s 447us/step - loss: 0.0040 - acc: 0.9987 - val_loss: 3.4332e-05 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "792/792 [==============================] - 0s 454us/step - loss: 1.9937e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "792/792 [==============================] - 0s 454us/step - loss: 3.2553e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "792/792 [==============================] - 0s 458us/step - loss: 6.1011e-04 - acc: 1.0000 - val_loss: 6.5873e-06 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "792/792 [==============================] - 0s 545us/step - loss: 3.3483e-04 - acc: 1.0000 - val_loss: 8.9974e-06 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "792/792 [==============================] - 0s 410us/step - loss: 3.2849e-04 - acc: 1.0000 - val_loss: 1.0471e-05 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "792/792 [==============================] - 0s 448us/step - loss: 0.0153 - acc: 0.9975 - val_loss: 1.1407e-04 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "792/792 [==============================] - 0s 372us/step - loss: 2.5886e-04 - acc: 1.0000 - val_loss: 2.5421e-04 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "792/792 [==============================] - 0s 388us/step - loss: 1.9826e-04 - acc: 1.0000 - val_loss: 1.6690e-06 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "792/792 [==============================] - 0s 529us/step - loss: 3.0789e-04 - acc: 1.0000 - val_loss: 2.3974e-06 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "792/792 [==============================] - 0s 496us/step - loss: 0.0037 - acc: 0.9987 - val_loss: 1.7476e-06 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "792/792 [==============================] - 0s 466us/step - loss: 2.5085e-04 - acc: 1.0000 - val_loss: 5.9729e-05 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "792/792 [==============================] - 0s 600us/step - loss: 0.0064 - acc: 0.9987 - val_loss: 5.6851e-05 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "792/792 [==============================] - 0s 589us/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0037 - val_acc: 0.9949\n",
      "Epoch 44/50\n",
      "792/792 [==============================] - 0s 455us/step - loss: 8.2255e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "792/792 [==============================] - 0s 551us/step - loss: 5.4967e-04 - acc: 1.0000 - val_loss: 8.8145e-06 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "792/792 [==============================] - 0s 459us/step - loss: 0.0065 - acc: 0.9987 - val_loss: 2.3915e-05 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "792/792 [==============================] - 0s 473us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "792/792 [==============================] - 0s 463us/step - loss: 3.3329e-05 - acc: 1.0000 - val_loss: 7.9940e-04 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "792/792 [==============================] - 0s 468us/step - loss: 0.0058 - acc: 0.9987 - val_loss: 0.0516 - val_acc: 0.9949\n",
      "Epoch 50/50\n",
      "792/792 [==============================] - 0s 479us/step - loss: 1.0692e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18dc137f0>"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model3.fit(train_x, train_y, epochs = 50, verbose=1, validation_data=(validate_x_3, validate_y_3), callbacks=[history3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Models\n",
    "\n",
    "Trained model information is saved for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1.save('models/model_1_0.29073.h5')\n",
    "#model2.save('models/model_2_0.29073.h5')\n",
    "#model3.save('models/model_3_0.29073.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same data pre-processing procedures on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_frame = pd.read_csv(LABEL_PATH + TEST_FILE_NAME)\n",
    "\n",
    "index = test_data_frame.pop('id')\n",
    "\n",
    "test_x = StandardScaler().fit(test_data_frame).transform(test_data_frame)\n",
    "#test_x = test_data_frame.get_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separately use the 3 models to predict the results based on the test X values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_1 = model1.predict_classes(test_x)\n",
    "test_y_2 = model2.predict_classes(test_x)\n",
    "test_y_3 = model3.predict_classes(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A summarised `test_y` object is generated and sorted by `loss` in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'test_y_1', 'loss': 2.1263915479694056e-05},\n",
       " {'name': 'test_y_2', 'loss': 0.00044629544951742836},\n",
       " {'name': 'test_y_3', 'loss': 0.00010692008211460941}]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = [\n",
    "    {\n",
    "        'name': 'test_y_1',\n",
    "        'predict': test_y_1,\n",
    "        'loss': history1.history['loss'][-1]\n",
    "    }, \n",
    "    {\n",
    "        'name': 'test_y_2',\n",
    "        'predict': test_y_2,\n",
    "        'loss': history2.history['loss'][-1]\n",
    "    }, \n",
    "    {\n",
    "        'name': 'test_y_3',\n",
    "        'predict': test_y_3,\n",
    "        'loss': history3.history['loss'][-1]\n",
    "    }, \n",
    "]\n",
    "\n",
    "test_y = sorted(test_y, key=lambda k: k['loss'])\n",
    "\n",
    "losses = [\n",
    "    {\n",
    "        'name': 'test_y_1',\n",
    "        'loss': history1.history['loss'][-1]\n",
    "    }, {\n",
    "        'name': 'test_y_2',\n",
    "        'loss': history2.history['loss'][-1]\n",
    "    }, {\n",
    "        'name': 'test_y_3',\n",
    "        'loss': history3.history['loss'][-1]\n",
    "    }, \n",
    "]\n",
    "\n",
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data_grid` is used to store the generated the file format which Kaggle competition will accept.\n",
    "\n",
    "Then iterate every predicted data and compare the results in the 3 models. \n",
    "\n",
    "If 2 or more models predict the same class, it will be the actual predicted class.\n",
    "\n",
    "If 3 models all predict different classes, then the value of the model with the least loss will be athe actual predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{51: 3}\n",
      "{50: 3}\n",
      "{1: 3}\n",
      "{19: 3}\n",
      "{14: 3}\n",
      "{3: 3}\n",
      "{3: 3}\n",
      "{28: 3}\n",
      "{84: 3}\n",
      "{8: 3}\n",
      "{43: 3}\n",
      "{74: 3}\n",
      "{75: 3}\n",
      "{10: 3}\n",
      "{52: 3}\n",
      "{46: 3}\n",
      "{45: 3}\n",
      "{73: 3}\n",
      "{13: 3}\n",
      "{71: 3}\n",
      "{61: 3}\n",
      "{68: 3}\n",
      "{57: 3}\n",
      "{77: 3}\n",
      "{1: 3}\n",
      "{70: 3}\n",
      "{28: 3}\n",
      "{15: 3}\n",
      "{35: 3}\n",
      "{70: 3}\n",
      "{53: 3}\n",
      "{74: 3}\n",
      "{47: 3}\n",
      "{50: 3}\n",
      "{4: 3}\n",
      "{36: 3}\n",
      "{14: 3}\n",
      "{55: 3}\n",
      "{36: 3}\n",
      "{93: 3}\n",
      "{8: 3}\n",
      "{32: 3}\n",
      "{8: 3}\n",
      "{9: 3}\n",
      "{71: 3}\n",
      "{70: 3}\n",
      "{38: 3}\n",
      "{23: 3}\n",
      "{94: 3}\n",
      "{18: 3}\n",
      "{17: 3}\n",
      "{5: 3}\n",
      "{55: 3}\n",
      "{94: 3}\n",
      "{14: 3}\n",
      "{86: 3}\n",
      "{62: 3}\n",
      "{33: 3}\n",
      "{51: 3}\n",
      "{98: 3}\n",
      "{88: 3}\n",
      "{56: 3}\n",
      "{21: 3}\n",
      "{59: 3}\n",
      "{65: 3}\n",
      "{11: 3}\n",
      "{48: 3}\n",
      "{5: 3}\n",
      "{13: 3}\n",
      "{4: 3}\n",
      "{54: 3}\n",
      "{57: 3}\n",
      "{29: 3}\n",
      "{7: 3}\n",
      "{31: 3}\n",
      "{98: 3}\n",
      "{92: 3}\n",
      "{84: 3}\n",
      "{25: 3}\n",
      "{10: 3}\n",
      "{61: 3}\n",
      "{43: 3}\n",
      "{85: 3}\n",
      "{24: 3}\n",
      "{1: 3}\n",
      "{2: 3}\n",
      "{23: 3}\n",
      "{83: 3}\n",
      "{40: 2, 39: 1}\n",
      "{22: 3}\n",
      "{48: 3}\n",
      "{90: 3}\n",
      "{25: 3}\n",
      "{21: 3}\n",
      "{37: 3}\n",
      "{56: 3}\n",
      "{41: 3}\n",
      "{95: 3}\n",
      "{7: 3}\n",
      "{89: 3}\n",
      "{98: 3}\n",
      "{77: 3}\n",
      "{3: 3}\n",
      "{12: 3}\n",
      "{31: 3}\n",
      "{84: 3}\n",
      "{53: 3}\n",
      "{96: 3}\n",
      "{64: 3}\n",
      "{72: 3}\n",
      "{93: 3}\n",
      "{93: 3}\n",
      "{67: 3}\n",
      "{30: 3}\n",
      "{8: 3}\n",
      "{88: 3}\n",
      "{60: 3}\n",
      "{87: 3}\n",
      "{6: 3}\n",
      "{57: 3}\n",
      "{34: 3}\n",
      "{90: 3}\n",
      "{60: 3}\n",
      "{17: 3}\n",
      "{75: 3}\n",
      "{27: 3}\n",
      "{51: 3}\n",
      "{31: 2, 44: 1}\n",
      "{39: 3}\n",
      "{23: 3}\n",
      "{29: 1, 38: 1, 24: 1}\n",
      "{2: 3}\n",
      "{41: 3}\n",
      "{61: 3}\n",
      "{24: 3}\n",
      "{97: 3}\n",
      "{29: 3}\n",
      "{28: 3}\n",
      "{68: 3}\n",
      "{81: 3}\n",
      "{42: 3}\n",
      "{51: 3}\n",
      "{86: 3}\n",
      "{62: 3}\n",
      "{60: 3}\n",
      "{52: 3}\n",
      "{95: 3}\n",
      "{64: 3}\n",
      "{42: 3}\n",
      "{96: 3}\n",
      "{95: 3}\n",
      "{20: 3}\n",
      "{59: 3}\n",
      "{35: 3}\n",
      "{86: 3}\n",
      "{1: 3}\n",
      "{26: 3}\n",
      "{38: 3}\n",
      "{43: 3}\n",
      "{75: 3}\n",
      "{20: 3}\n",
      "{60: 3}\n",
      "{46: 3}\n",
      "{79: 3}\n",
      "{22: 3}\n",
      "{79: 3}\n",
      "{69: 3}\n",
      "{87: 3}\n",
      "{65: 3}\n",
      "{97: 3}\n",
      "{75: 3}\n",
      "{21: 3}\n",
      "{29: 3}\n",
      "{21: 3}\n",
      "{11: 3}\n",
      "{10: 3}\n",
      "{58: 3}\n",
      "{94: 3}\n",
      "{27: 3}\n",
      "{22: 3}\n",
      "{15: 3}\n",
      "{45: 3}\n",
      "{89: 3}\n",
      "{54: 3}\n",
      "{43: 3}\n",
      "{5: 3}\n",
      "{23: 3}\n",
      "{94: 3}\n",
      "{40: 3}\n",
      "{49: 3}\n",
      "{89: 3}\n",
      "{72: 3}\n",
      "{36: 3}\n",
      "{11: 3}\n",
      "{81: 3}\n",
      "{95: 3}\n",
      "{18: 3}\n",
      "{91: 3}\n",
      "{29: 3}\n",
      "{64: 3}\n",
      "{80: 3}\n",
      "{6: 3}\n",
      "{78: 3}\n",
      "{45: 3}\n",
      "{28: 3}\n",
      "{9: 3}\n",
      "{78: 3}\n",
      "{90: 3}\n",
      "{44: 3}\n",
      "{89: 3}\n",
      "{92: 3}\n",
      "{13: 3}\n",
      "{2: 3}\n",
      "{59: 3}\n",
      "{0: 3}\n",
      "{96: 3}\n",
      "{70: 3}\n",
      "{32: 3}\n",
      "{29: 3}\n",
      "{78: 3}\n",
      "{91: 3}\n",
      "{55: 3}\n",
      "{44: 3}\n",
      "{38: 3}\n",
      "{5: 3}\n",
      "{60: 3}\n",
      "{49: 3}\n",
      "{58: 3}\n",
      "{94: 3}\n",
      "{67: 3}\n",
      "{92: 2, 7: 1}\n",
      "{88: 3}\n",
      "{90: 3}\n",
      "{79: 3}\n",
      "{25: 3}\n",
      "{37: 3}\n",
      "{18: 3}\n",
      "{0: 3}\n",
      "{76: 3}\n",
      "{27: 3}\n",
      "{70: 3}\n",
      "{71: 3}\n",
      "{44: 3}\n",
      "{70: 3}\n",
      "{32: 3}\n",
      "{90: 3}\n",
      "{30: 3}\n",
      "{82: 3}\n",
      "{34: 3}\n",
      "{30: 3}\n",
      "{82: 3}\n",
      "{96: 3}\n",
      "{48: 3}\n",
      "{65: 3}\n",
      "{57: 3}\n",
      "{64: 3}\n",
      "{26: 3}\n",
      "{53: 3}\n",
      "{55: 3}\n",
      "{73: 3}\n",
      "{9: 3}\n",
      "{3: 3}\n",
      "{83: 3}\n",
      "{26: 3}\n",
      "{30: 3}\n",
      "{63: 3}\n",
      "{17: 3}\n",
      "{22: 3}\n",
      "{79: 3}\n",
      "{63: 3}\n",
      "{12: 3}\n",
      "{78: 3}\n",
      "{36: 2, 38: 1}\n",
      "{14: 3}\n",
      "{27: 3}\n",
      "{25: 3}\n",
      "{67: 3}\n",
      "{38: 3}\n",
      "{20: 3}\n",
      "{54: 3}\n",
      "{76: 3}\n",
      "{69: 3}\n",
      "{67: 2, 87: 1}\n",
      "{97: 3}\n",
      "{80: 3}\n",
      "{44: 3}\n",
      "{92: 3}\n",
      "{69: 3}\n",
      "{23: 3}\n",
      "{21: 3}\n",
      "{16: 3}\n",
      "{51: 3}\n",
      "{33: 3}\n",
      "{77: 3}\n",
      "{16: 3}\n",
      "{11: 3}\n",
      "{97: 3}\n",
      "{1: 3}\n",
      "{52: 3}\n",
      "{39: 3}\n",
      "{24: 3}\n",
      "{52: 3}\n",
      "{42: 3}\n",
      "{17: 2, 52: 1}\n",
      "{2: 3}\n",
      "{73: 3}\n",
      "{96: 3}\n",
      "{83: 3}\n",
      "{88: 3}\n",
      "{9: 3}\n",
      "{63: 3}\n",
      "{50: 3}\n",
      "{16: 3}\n",
      "{37: 1, 38: 2}\n",
      "{87: 3}\n",
      "{95: 3}\n",
      "{3: 3}\n",
      "{35: 3}\n",
      "{83: 3}\n",
      "{60: 3}\n",
      "{59: 3}\n",
      "{58: 3}\n",
      "{0: 3}\n",
      "{50: 3}\n",
      "{62: 3}\n",
      "{38: 3}\n",
      "{93: 3}\n",
      "{68: 3}\n",
      "{53: 2, 56: 1}\n",
      "{46: 3}\n",
      "{19: 3}\n",
      "{46: 3}\n",
      "{94: 3}\n",
      "{18: 3}\n",
      "{0: 3}\n",
      "{33: 3}\n",
      "{89: 3}\n",
      "{40: 2, 39: 1}\n",
      "{62: 3}\n",
      "{48: 3}\n",
      "{42: 3}\n",
      "{6: 3}\n",
      "{31: 3}\n",
      "{91: 3}\n",
      "{73: 3}\n",
      "{81: 3}\n",
      "{12: 3}\n",
      "{85: 3}\n",
      "{47: 3}\n",
      "{6: 3}\n",
      "{79: 1, 45: 2}\n",
      "{2: 3}\n",
      "{22: 3}\n",
      "{35: 3}\n",
      "{43: 3}\n",
      "{6: 3}\n",
      "{80: 3}\n",
      "{78: 3}\n",
      "{82: 3}\n",
      "{5: 3}\n",
      "{61: 3}\n",
      "{37: 3}\n",
      "{43: 3}\n",
      "{33: 3}\n",
      "{69: 3}\n",
      "{56: 3}\n",
      "{71: 3}\n",
      "{45: 3}\n",
      "{59: 3}\n",
      "{42: 3}\n",
      "{66: 3}\n",
      "{86: 3}\n",
      "{98: 3}\n",
      "{83: 3}\n",
      "{90: 3}\n",
      "{64: 3}\n",
      "{82: 3}\n",
      "{11: 3}\n",
      "{79: 3}\n",
      "{56: 3}\n",
      "{76: 3}\n",
      "{49: 3}\n",
      "{48: 3}\n",
      "{20: 3}\n",
      "{74: 3}\n",
      "{15: 3}\n",
      "{33: 3}\n",
      "{49: 3}\n",
      "{89: 3}\n",
      "{44: 3}\n",
      "{7: 3}\n",
      "{35: 3}\n",
      "{14: 3}\n",
      "{55: 3}\n",
      "{23: 3}\n",
      "{34: 3}\n",
      "{44: 3}\n",
      "{32: 3}\n",
      "{30: 3}\n",
      "{36: 3}\n",
      "{9: 3}\n",
      "{72: 3}\n",
      "{31: 3}\n",
      "{61: 3}\n",
      "{50: 3}\n",
      "{82: 3}\n",
      "{34: 3}\n",
      "{29: 2, 28: 1}\n",
      "{22: 3}\n",
      "{92: 3}\n",
      "{72: 3}\n",
      "{11: 3}\n",
      "{19: 3}\n",
      "{4: 3}\n",
      "{87: 3}\n",
      "{51: 3}\n",
      "{71: 2, 80: 1}\n",
      "{39: 3}\n",
      "{84: 3}\n",
      "{32: 3}\n",
      "{66: 3}\n",
      "{36: 3}\n",
      "{41: 3}\n",
      "{31: 3}\n",
      "{80: 3}\n",
      "{4: 3}\n",
      "{26: 3}\n",
      "{68: 3}\n",
      "{96: 3}\n",
      "{20: 3}\n",
      "{40: 2, 39: 1}\n",
      "{34: 3}\n",
      "{39: 3}\n",
      "{56: 3}\n",
      "{73: 3}\n",
      "{76: 3}\n",
      "{84: 3}\n",
      "{7: 3}\n",
      "{67: 3}\n",
      "{37: 3}\n",
      "{8: 3}\n",
      "{95: 3}\n",
      "{85: 3}\n",
      "{62: 3}\n",
      "{10: 3}\n",
      "{65: 3}\n",
      "{41: 2, 48: 1}\n",
      "{2: 3}\n",
      "{17: 2, 94: 1}\n",
      "{86: 3}\n",
      "{41: 3}\n",
      "{52: 3}\n",
      "{3: 3}\n",
      "{49: 3}\n",
      "{47: 3}\n",
      "{76: 3}\n",
      "{52: 3}\n",
      "{16: 3}\n",
      "{26: 3}\n",
      "{88: 3}\n",
      "{63: 3}\n",
      "{45: 3}\n",
      "{39: 3}\n",
      "{66: 3}\n",
      "{87: 3}\n",
      "{75: 3}\n",
      "{74: 3}\n",
      "{7: 3}\n",
      "{64: 3}\n",
      "{65: 3}\n",
      "{78: 3}\n",
      "{63: 3}\n",
      "{56: 3}\n",
      "{21: 3}\n",
      "{61: 3}\n",
      "{88: 3}\n",
      "{62: 3}\n",
      "{91: 3}\n",
      "{59: 3}\n",
      "{12: 3}\n",
      "{74: 3}\n",
      "{15: 3}\n",
      "{85: 3}\n",
      "{8: 3}\n",
      "{66: 3}\n",
      "{57: 3}\n",
      "{83: 3}\n",
      "{82: 3}\n",
      "{72: 3}\n",
      "{58: 3}\n",
      "{28: 3}\n",
      "{17: 3}\n",
      "{67: 2, 87: 1}\n",
      "{66: 3}\n",
      "{57: 3}\n",
      "{66: 3}\n",
      "{75: 3}\n",
      "{35: 3}\n",
      "{18: 3}\n",
      "{9: 3}\n",
      "{54: 3}\n",
      "{91: 3}\n",
      "{65: 3}\n",
      "{19: 3}\n",
      "{15: 3}\n",
      "{10: 3}\n",
      "{24: 3}\n",
      "{71: 3}\n",
      "{69: 3}\n",
      "{48: 3}\n",
      "{39: 3}\n",
      "{98: 3}\n",
      "{16: 3}\n",
      "{19: 3}\n",
      "{45: 3}\n",
      "{74: 3}\n",
      "{6: 3}\n",
      "{67: 1, 69: 1, 81: 1}\n",
      "{42: 3}\n",
      "{34: 3}\n",
      "{71: 3}\n",
      "{47: 3}\n",
      "{85: 3}\n",
      "{28: 3}\n",
      "{85: 3}\n",
      "{47: 3}\n",
      "{25: 3}\n",
      "{27: 3}\n",
      "{58: 3}\n",
      "{68: 3}\n",
      "{84: 3}\n",
      "{97: 3}\n",
      "{82: 1, 63: 2}\n",
      "{97: 3}\n",
      "{76: 3}\n",
      "{81: 3}\n",
      "{87: 3}\n",
      "{77: 3}\n",
      "{13: 3}\n",
      "{0: 3}\n",
      "{28: 3}\n",
      "{41: 3}\n",
      "{14: 3}\n",
      "{12: 3}\n",
      "{33: 3}\n",
      "{86: 2, 69: 1}\n",
      "{46: 3}\n",
      "{4: 3}\n",
      "{4: 3}\n",
      "{47: 3}\n",
      "{30: 3}\n",
      "{19: 3}\n",
      "{58: 3}\n",
      "{13: 3}\n",
      "{77: 3}\n",
      "{98: 3}\n",
      "{5: 3}\n",
      "{49: 3}\n",
      "{72: 3}\n",
      "{53: 3}\n",
      "{32: 3}\n",
      "{77: 3}\n",
      "{40: 3}\n",
      "{68: 3}\n",
      "{26: 3}\n",
      "{92: 3}\n",
      "{16: 3}\n",
      "{81: 3}\n",
      "{37: 3}\n",
      "{14: 3}\n",
      "{93: 3}\n",
      "{80: 3}\n",
      "{53: 3}\n",
      "{46: 3}\n",
      "{25: 3}\n",
      "{50: 3}\n",
      "{7: 3}\n",
      "{37: 3}\n",
      "{93: 3}\n",
      "{0: 3}\n",
      "{20: 3}\n",
      "{54: 3}\n",
      "{10: 3}\n",
      "{91: 3}\n",
      "{40: 3}\n",
      "{81: 3}\n",
      "{53: 3}\n",
      "{18: 3}\n",
      "{27: 3}\n",
      "{1: 3}\n",
      "{12: 3}\n",
      "{54: 3}\n",
      "{73: 3}\n",
      "{15: 3}\n"
     ]
    }
   ],
   "source": [
    "data_grid = np.zeros((len(test_y_1), len(classes)))\n",
    "\n",
    "for i in range(len(test_y_1)):\n",
    "    count = {}\n",
    "    for test in test_y:\n",
    "        if test['predict'][i] not in count:\n",
    "            count[test['predict'][i]] = 1\n",
    "        else:\n",
    "            count[test['predict'][i]] += 1\n",
    "    \n",
    "    result = Counter(count)\n",
    "    predicted = result.most_common(1)\n",
    "    data_grid[i][predicted[0][0]] = 1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `pd.DataFrame` to generate CSV format variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(data_grid, index = index, columns = classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, write the variable into the CSV file for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission.csv','w') as file:\n",
    "    file.write(prediction.to_csv())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the same directory, run `kaggle competitions submit -c leaf-classification -f submission.csv -m \"Message\"` command to submit the CSV file to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
